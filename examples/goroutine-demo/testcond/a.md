## 语言篇
### GO语言基础
#### 1. 与其他语言相比，GO语言有什么优势？
题解：问的是GO的优势，需要对比一下其他语言。GO 对上 C/C++ 、JAVA 、PHP/Python。
核心要答出来，GO的并发优势。
- go语法简单，包含了类C语法，学习曲线比较容易。
- 相较于java的编译速度，go代码编译速度不仅快，且Go拥有接近C的运行效率和接近python的开发效率
- go具有方便的内存分配、垃圾回收机制和强大的运行时反射机制。go支持轻量级的线程（称为 goroutines）和通信机制（称为 channels），这种并发模型可以轻松实现高性能的并发程序。
- Go语言的编译器可以将所有依赖项静态链接到二进制文件中，使程序的部署变得简单。go编译生成的二进制文件可以在多个平台上运行，所以go语言支持跨平台，但是C语言的编译器生成本地机器指令，因此需要为每个平台编译不同的二进制文件。

#### 2. GO使用的数据类型有哪些？
题解：明面上问的是有哪些数据类型，实际上如果问题展开的话，还有分更多的种类，比如值类型，引用类型。引用中的可比较和不可比较类型。
go语言数据类型可以分为值类型和引用类型，而引用类型又分为可比较和不可比较（例如比较操作符（如 == 、 !=、>=等））
- 值类型：byte、rune、string、int、uint、float32 64、bool 、数组、结构体
- 可比较的引用数据类型：切片、map、函数类型
- 可比较的引用数据类型：指针、channel
#### 3. GO的类型转换和类型推断是什么？
在Go语言中，类型转换（type conversion）是指将一个类型的值转换为另一个类型的值。类型转换可以发生在数值类型之间、字符串类型和数值类型之间、布尔类型和数值类型之间等类型之间。
- 类型转换的方法：显示类型转换、隐式类型转换、 类型断言 、重新构造对象
- 类型推断：类型推断（type inference）是一种在编程语言中自动推断变量类型的机制。在Go语言中，类型推断通常用于变量声明和初始化，可以通过短变量声明语法来自动推断变量类型。结构体可以使用反射来获取和修改其字段的值，因此可以说结构体是可以反转的。反转指的是在运行时动态地获取和修改结构体的属性或字段，而不需要事先知道结构体的具体类型和结构。
#### 4. GO语言中Channel有什么特点。读写一个已关闭的Channel会发生什么？
- channe俗称：通道，是GO语言所有基础类型中唯一的满足并发安全的类型。
首先go语言中的channel 具有以下四个特点：
- Channel是类型安全的，可以确保发送和接收的数据类型一致。
- Channel是阻塞的，当发送或接收操作没有被满足时，会阻塞当前goroutine，直到满足条件。
- Channel是有缓存的，可以指定缓存区大小，当缓存区已满时发送操作会被阻塞，当缓存区为空时接收操作会被阻塞。
- Channel是可以关闭的，可以使用close()函数关闭Channel，关闭后的Channel不能再进行发送操作，但可以进行接收操作。
读写一个已关闭的Channel：
1.    有缓存的 channel：如果读取一个已关闭的有缓存的 channel，则会一直读取其中已有的值，直到 channel 中的所有值都被读取完毕，然后读取操作会立即返回一个零值和一个布尔值 false，表示 channel 已经关闭了。如果向一个已关闭的有缓存的 channel 中写入数据，写入操作会导致 panic 异常，因为写入已关闭的 channel 是非法的操作。
2.    无缓存的 channel：如果读取一个已关闭的无缓存的 channel，读取操作会立即返回一个零值和一个布尔值 false，表示 channel 已经关闭了。如果向一个已关闭的无缓存的 channel 中写入数据，写入操作会导致 panic 异常，因为写入已关闭的 channel 是非法的操作。
#### 5.Go语言中New和Make有什么区别？简单讲讲他们的用法。
1.    make：用于创建切片、映射(map)和通道(channel)这三种数据结构，并初始化其内部数据结构，返回一个已初始化的对象。make 接受两个参数，第一个参数是类型，第二个参数是长度或容量等参数，具体取决于类型。例如，创建一个长度为 10 的整型切片，可以使用以下代码：
2.    new 是一个内置函数，用于创建任何类型的数据结构，并返回一个指向该类型零值的指针。。new 函数只会分配内存并返回一个指向该类型零值的指针，它不会初始化结构体中的字段或数组中的元素，因此需要注意在使用指针时，应该确保其已经初始化，否则可能会导致运行时错误。
#### 6.如何理解GO语言中的值传递。“GO不存在指针或者引用传递”应该如何理解。
1.    值传递是指在调用函数时将实际参数复制一份传递到函数中，这样在函数中如果对参数进行修改，将不会影响到实际参数。
2.    Go中的引用类型在进行参数传递时传递的是指针的拷贝,属于值转递,但是这个指针拷贝仍然指向同一数据,所以可以在函数内部修改这些类型的变量的内容.
#### 7.GO语言中数组和切片有什么区别？
在Go语言中，数组和切片都是用于存储一组数据的数据结构，Go 语言的切片类型属于引用类型，同属引用类型的还有字典类型、通道类型、函数类型等；而 Go 语言的数组类型则属于值类型，同属值类型的有基础数据类型以及结构体类型。它们有以下几个区别：
- 定义方式不同：数组的定义方式为var array [length]Type，其中length是数组的长度，Type是数组元素的类型；而切片的定义方式为var slice []Type，其中Type是切片元素的类型。
- 容量和长度不同：数组的长度是固定的，定义数组时就需要指定长度；而切片的长度和容量都可以动态变化。
- 内存分配方式不同：数组是静态分配的，即在编译时就已经分配好了内存空间；而切片是动态分配的，即在运行时根据需要动态自动分配内存空间。
- 传递方式不同：数组作为函数参数时传递的是整个数组的副本，即在函数内部无法修改原始数组；而切片作为函数参数时传递的是切片的引用，即在函数内部可以修改原始切片。
- 值类型和引用类型不同：数组是值类型，赋值和传递时会复制整个数组；而切片是引用类型，赋值和传递时只会复制指向底层数组的指针、长度和容量等元数据。
- 总的来说，数组适合存储固定长度的数据，切片适合存储动态长度的数据。在实际开发中，切片的使用更加灵活和方便，而数组的使用场景相对较少，通常用于特定的场景，如算法实现、内存池等。
#### 8.切片是如何扩容的。有哪些规则？
1.    Go 1.17前——切片扩容时会进行内存对齐，这个和内存分配策略相关。进行内存对齐之后，新`slice` 的容量是要大于等于老 slice 容量的 2倍或者1.25倍。
- 当新切片需要的容量cap大于两倍扩容的容量，则直接按照新切片需要的容量扩容；
- 当原 slice 容量 < 1024 的时候，新 slice 容量变成原来的 2 倍；
- 当原 slice 容量 > 1024，进入一个循环，每次容量变成原来的1.25倍,直到大于期望容量。
2.    Go1.18后——不再以1024为临界点，而是设定了一个值为256的threshold，以256为临界点；超过256，不再是每次扩容1/4，而是每次增加（旧容量+3*256）/4；
- 当新切片需要的容量cap大于两倍扩容的容量，则直接按照新切片需要的容量扩容；
- 当原 slice 容量 < threshold 的时候，新 slice 容量变成原来的 2 倍；
- 当原 slice 容量 > threshold，进入一个循环，每次容量增加（旧容量+3*threshold）/4。
#### 9.GO语言的异常处理是如何实现的。panic和recover的实现。
- 异常处理的目的是保证程序的健壮性和稳定性，避免程序崩溃或产生不可预期的错误。go语言通常使用panic和recover进行异常处理。
1. painc 可以是系统出现严重错误时产生，也可以人为调用painc函数；一旦painc被触发，程序会从当前调用栈中一层层地回退，直到找到第一个能够处理该异常的recover语句。
2. recover 函数只能在Defer中，并且存在一个painc 的时候才会生效，把painc 的recovered属性设置为true，然后返回一个空接口。若当前GoRoutine中没有painc，则返回nil。
3. Panic 是链状保存的,最新形成的panic放在链表的首部，并且painc 只会触发自己所在的GoRoutine中的Defer里的recover函数。
4. 执行painc的是runtime.gopanic函数。在这里，他依赖Defer，也会响应recover的操作。在异常被恢复情况下，会一直走到deferreturn中，最终恢复现场。否则，会执行fatalpanic函数，打印出调用栈和异常信息，最后系统退出，显示错误码2。
#### 10.GO语言的错误处理。
1. 首先，go语言的错误是一个error类型。
2. 当出现错误时，通常返回一个错误值来实现的，这个错误值通过error类型Error方法来存储，并且是一个字符串类型，一般通过打印error.Error()来帮助程序员对程序调试和维护。而且出现错误时并不会直接终止程序。
3. 当没有错误时，error会返回一个nil，代表返回错误的代码块没有出现错误。
4. 除此之外，还有panic和recovery来处理严重不可恢复的错误，这两个一般都会谨慎使用。
#### 11.Defer在使用中有哪些需要注意的地方？
题解：Go中的defer是做什么的，执行顺序是怎么样的；defer遇见panic会发生什么；defer下的函数参数包含子函数。
1.defer是一种延迟执行机制，是在函数进行return之前进行执行，defer可以在函数任意位置定义，但是在函数结束之后，所有的defer语句都会被执行。defer的执行顺序采用的是栈的方法执行，也就是说先被定义的defer后执行，后定义的defer先执行。
2.当函数中发生panic异常，会马上终止当前函数的执行，panic之前定义的defer会被执行。要想在defer中获取到具体的panic信息，需要使用 recover() 进行获取。
3.当defer中存在子函数时，子函数按照defer定义的语句顺序 ，优先执行。defer最外层的逻辑依旧按照栈的形式进行。
#### 12.GO语言的MAP的底层原理，它是如何实现扩容的。
Map的底层实现原理就是哈希（hash）扩容的时机：装载因子超过一定的阈值或者使用了太多的溢出桶时。
扩容的规则：
1.等量扩容 使用溢出桶太多的时候会进行等量扩容。申请和原来等量的内容，将原来的数据重新整理后，写入到新的内存中。可以简单的认为是一次内存整理，目的是提高查询效率。
2.增量扩容 分成两步： 第一步进入扩容状态，先申请一块新的内存，翻倍增加桶的数量，此时buckets指向新分配的桶，oldbuckets指向原来的桶。 第二步，重新计算老的桶中的哈希值在新的桶内的位置（取模或者位操作），将旧数据用渐进式的方式拷贝到新的桶中。
渐进式迁移分两块，一方面会从第一个桶开始，顺序迁移每一个桶，如果下一个桶已经迁移，则跳过。另一方面，当我们操作某一个桶的元素时，会迁移两个桶，进而保证经过一些操作后一定能够完成迁移。
当我们访问一个正在迁移的Map时，如果存在oldbuckets，那么直接去中oldbuckets寻找数据。当我们遍历一个正在迁移的Map时，新的和旧的就会遍历，如果一个旧的的桶已经迁移走了，那么就直接跳过，反正不在旧的就在新的里。Map遍历本身就是无序的。
#### 13.GO语言的逃逸分析是什么。哪些情况会出现逃逸。
应用程序的内存载体，可以简单地将其分为堆和栈
在Go中，栈的内存是由编译器自动进行分配和释放，栈区往往存储着函数参数、局部变量和调用函数帧，它们随着函数的创建而分配，函数的退出而销毁。一个goroutine对应一个栈.与栈不同的是，应用程序在运行时只会存在一个堆。狭隘地说，内存管理只是针对堆内存而言的。程序在运行期间可以主动从堆上申请内存，这些内存通过Go的内存分配器分配，并由垃圾收集器回收。
GO语言编译器在编译时会将变量分配到栈上或堆上,如果可以，Go编译器会尽可能将变量分配到到栈上。但是有时候变量必须要被分配到堆上。Go语言的逃逸分析就是用来判断一个变量是应该分配在栈上还是堆上。它可以帮助编译器在编译期间对程序的内存分配进行优化。一般来说，如果一个变量的生命周期是完全可知的，并且没有被函数外部引用，那么它就可以分配在栈上；否则，它就会发生逃逸，必须分配在堆上。
会出现逃逸分析的情况:
1. 参数是interface类型
2. 变量在函数外部有引用
3. 变量内存占用较大
4. 变量大小不确定.
### GO并发编程
#### 14.Mutex包的功能和用法。（Mutex的4种状态，正常模式和饥饿模式，自旋）
- Mutex包给go语言提供了互斥锁的功能,其内部有两个字段:state和sema.state表示互斥锁的状态,sema表示信号量.state是32位整型变量,内部被分成四份,用于记录mutex的4种状态.
- Locked: 表示该Mutex是否已被锁定，0：没有锁定 1：已被锁定。
- Woken: 表示是否有协程已被唤醒，0：没有协程唤醒 1：已有协程唤醒，正在加锁过程中。
- Starving：表示该Mutex是否处于饥饿状态， 0：没有饥饿 1：饥饿状态，说明有协程阻塞了超过1ms。
- Waiter: 表示阻塞等待锁的协程个数，协程解锁时根据此值来判断是否需要释放信号量。
- Mutex只对外提供两个方法:Lock():加锁方法和Unlock():解锁方法.加锁时，如果当前Locked位为1，说明该锁当前由其他协程持有，尝试加锁的协程并不是马上转入阻塞，而是会持续的探测Locked位是否变为0，这个过程即为自旋过程。自旋的好处是，当加锁失败时不必立即转入阻塞，有一定机会获取到锁，这样可以避免协程的切换。
- 每个Mutex都有两个模式，称为Normal和Starving。即正常模式和饥饿模式。在正常模式下,协程如果加锁不成功不会立即转入阻塞排队，而是判断是否满足自旋的条件，如果满足则会启动自旋过程，尝试抢锁。而一个已被阻塞的协程则会被再次阻塞,如果上次阻塞到本次阻塞的时间超过1ms,则会将mutex标为饥饿模式,在该模式下,不会启动自旋过程。
#### 15.RWMutex的功能实现和使用时的注意事项。
- Go 语言中，RWMutex 是基于互斥锁、变量、信号量等并发原语来实现的。Go 标准库中的 RWMutex 是基于 Mutex 实现的。
功能实现：
RWMutex 通过两个计数器来实现读写锁的功能：读计数器和写计数器。读计数器记录了当前有多少个读操作正在进行，写计数器则记录了当前是否有写操作正在进行。
注意事项：
1. 多个写操作不能同时进行，写操作和读操作也不能同时进行，但多个读操作却可以同时进行。
2. 对写锁进行解锁，会唤醒所有因试图锁定读锁，而被阻塞的goroutine。
3. 对读锁进行解锁，只会在没有其他读锁锁定的前提下，唤醒因试图锁定写锁，而被阻塞的 goroutine。
4. 读锁或写锁在未锁定状态，解锁操作都会引发 panic。
#### 16.Broadcast 和 single 的区别。
- Broadcast 和 single 分别表示广播通信和单播通信的概念，最常用来实现观察者模型。
#### 17.waitGroup的用法和实现原理。
题解：先介绍什么是waitGroup，然后介绍它的用法，最后介绍它的实现原理同时说一下注意事项
1. waitGroup是Go语言中用于同步多个goroutine的机制。在启动多个goroutine时，主goroutine可以通过waitGroup等待所有goroutine执行完成后再继续执行。waitGroup的主要作用是协调多个goroutine的执行顺序，避免出现竞争条件和数据竞争问题。
2. 在main函数或其他主goroutine中创建一个waitGroup对象；在每个goroutine启动前调用waitGroup的Add方法，增加计数器的值；在goroutine中执行相应的任务；在每个goroutine执行完成时，调用waitGroup的Done方法，减少计数器的值；在主goroutine中调用waitGroup的Wait方法，等待所有goroutine执行完成。
3. 在实现waitGroup的时候要用一个计数器初始值为0，当任务开始时候计数器加1，当任务结束时计时器减1。
4. 注意事项：Add和Done方法的调用次数需要匹配；避免在goroutine中复制waitGroup对象；不要在Done方法之前调用Wait方法；不要在多个waitGroup对象之间混淆使用；不要在Wait方法中修改计数器的值；避免在goroutine中调用Wait方法。 
#### 18.原子操作是什么，怎么实现，和锁的区别，CAS是什么。
1. 原子操作即是进行过程中不能被中断的操作，针对某个值的原子操作在被进行的过程中，CPU 绝不会再去进行其他的针对该值的操作。为了实现这样的严谨性，原子操作仅会由一个独立的 CPU 指令代表和完成。原子操作是无锁的，常常直接通过 CPU 指令直接实现。 事实上，其它同步技术的实现常常依赖于原子操作。
2. 原子操作由底层硬件支持，而锁则由操作系统的调度器实现。锁应当用来保护一段逻辑，对于一个变量更新的保护。
3. CAS（Compare and Swap）是一种常见的原子操作，是一种基于硬件原子指令的原子操作。CAS操作包含三个参数：内存位置（地址）、期望值和新值。它的执行步骤如下：
- ● 读取内存位置的当前值。
- ● 检查当前值是否等于期望值。
- ● 如果相等，将新值写入内存位置；如果不相等，说明其他线程已经修改了该值，则不进行写入，可以选择重试或放弃。
- CAS操作可以解决多线程环境下的竞态条件问题，并且在无竞争的情况下能够快速完成操作
#### 19.Sync包的功能和用法。主要是 Once 和Pool 的实现原理和具体用法。
- Sync包下有Mutex(互斥锁)、RWMutex(读写锁)、WaitGroup(等待组)、Cond(条件变量)、once(一次性执行)、map(并发安全映射表)
- sync.Pool 用于管理一组临时对象，并提供一种快速获取和释放这些对象的方法。它通常用于在多个 goroutine 中频繁创建和销毁某些对象时，以避免频繁地分配和释放内存。
- sync.Once 用于确保某个函数只会被执行一次。它通常用于在多个 goroutine 中共享某个资源时，以避免重复初始化该资源。
- RWmutex相当于在mutex的基础上再加一层的思想，将互斥操作分为读操作和写操作；mutex保证在同一时间只有一个线程可以访问共享资源， 
- Rwmutex：同一时间可以有多个线程访问资源(读操作)  。
- 举个例子：一个go runtine要读数据，需要检查公共资源的写锁是否被 go runtine拿走(不用管写锁);
- 一个go runtine要写数据，需要检查该公共资源的读写锁(两个锁都要检查)被goruntine拿走。
WaitGroup:创建：var wg sync.waitgroup;三个主要方法wg.add()：向waitgroup添加一个协程   wg.done()：关闭一个协程   wg.wait():主线程等待协程的执行
- Map:与原生的map的不一样,sync中的map是并发安全的，对键值的类型没有限制，在同一个map中可以存储多种不同的键值对，sync下的map用法:
load(取) 2.store(存)3.loadorstore(取不到就存进去)4.delete (删除)5.range(遍历)
#### 20.单飞
- SingleFlight即单飞包提供了一种抑制重复函数调用的机制.具体到Go程序运行的层面来说，SingleFlight的作用是在处理多个goroutine同时调用同一个函数的时候，只让一个goroutine去实际调用这个函数，等到这个goroutine返回结果的时候，再把结果返回给其他几个同时调用了相同函数的goroutine，这样可以减少并发调用的数量.通常用来防止缓存击穿。
- 缓存击穿:缓存在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。
- SingleFlight.Group类提供三个方法,分别为Do,DoChan,Forget.
- Do方法，接受一个字符串Key和一个待调用的函数，会返回调用函数的结果和错误。使用Do方法的时候，它会根据提供的Key判断是否去真正调用fn函数。同一个 key，在同一时间只有第一次调用Do方法时才会去执行fn函数，其他并发的请求会等待调用的执行结果。
- DoChan方法：类似Do方法，只不过是一个异步调用。它会返回一个通道，等fn函数执行完，产生了结果以后，就能从这个 chan 中接收这个结果。
- Forget方法：在SingleFlight中删除一个Key。这样一来，之后这个Key的Do方法调用会执行fn函数，而不是等待前一个未完成的fn 函数的结果。
### GO底层原理（难点）
#### 21.GO语言的GMP模型是什么，它是怎么调度的，随着版本迭代，GMP都做了哪些优化。
- GMP 模型是 Go 语言运行时系统中的一个关键组件，它用于管理内存分配和调度协程在多个线程之间的执行。
- G (groutine):G就是goroutine的意思, 代表了一个协程. 每次go调用的时候，都会创建一个G对象，它包括栈、指令指针以及对于调用goroutines很重要的其它信息，比如阻塞它的任何channel
- M(machine):M代表了一个线程 . 每次创建一个M的时候，都会有一个底层线程创建；所有的G任务，最终还是依附于M上执行
- P(processor):执行器或者处理器. 相当于一个管理者. 每一个M必须要绑定一个P. P自身有一个局部本地队列用来保存g. 并且所有的p都共享这一个全局队列。P负责调度goroutine，维护一个本地goroutine队列，M从P上获得goroutine并执行，同时还负责部分内存的管理。
调度顺序一图概括非常清楚
- 若局部队列满,入全局队列开始创建一个新的GOROUTINE入局部队列GO FUNC00P管理着自己的本地队列P管理着自己的本地队列M若是此M发送阻塞或者系统调用则P会与M解绑,在休眠队列中唤醒一P和M一一绑定M个M与之绑定,或者新建调度M执行时需要向P拿G一个M,然后执行GMCPU执行完销毁G1.M向P要G执行时,若是P自己的本地队列有G那么直然后返回接拿G来执行2.若是本地队列没有G,那么就去全局队列里面拿3.若是全局队列也没有G,那么就会去其他的MP组合里面抢夺GCSDN@水鱼老王
image.png

- 优化：
- 随着 Go 语言版本的迭代，GMP 模型也不断进行优化，以提高性能和可扩展性。例如，Go 1.5 版本引入了 GOMAXPROCS 环境变量，用于控制程序中并发执行的 P 实例数量，以提高程序的并发性能和扩展性。Go 1.8 版本引入了 M 增长机制，用于动态调整 M 实例的数量，以适应系统的负载变化。Go 1.14 版本引入了抢占式调度（Preemption），可以在协程执行时间过长时强制中断协程的执行，防止协程过度占用 CPU 时间。这些优化可以使 GMP 模型更加高效和灵活，适用于不同的应用场景和系统环境。
#### 22.调度机制有哪些？他们的原理是什么？
调度机制是指操作系统中用于管理和分配系统资源的一种机制。常见的调度机制包括：
1. 先来先服务（FCFS）：按照作业或进程到达的先后顺序进行调度。原理是按照请求的顺序进行处理，无关优先级或执行时间。
2. 最短作业优先（SJF）：选择估计执行时间最短的作业或进程进行调度。原理是通过预测执行时间，选择最短时间的作业先执行，以减少平均等待时间。
3. 优先级调度：为每个作业或进程分配一个优先级，并按照优先级进行调度。原理是根据作业或进程的重要性或紧急程度来确定执行顺序。
4. 时间片轮转（Round Robin）：将处理器时间分成一段段的时间片，每个作业或进程在一个时间片内运行，超过时间片后切换到下一个作业。原理是公平地分配处理器时间，避免长时间的等待。
5. 多级反馈队列调度：将作业或进程划分为多个优先级队列，并根据不同队列的优先级进行调度。原理是根据作业或进程的行为动态地调整其优先级，提高系统的响应性和吞吐量。
这些调度机制的原理和策略不同，目的是为了提高系统的性能、资源利用率和用户体验。具体选择哪种调度机制取决于系统的需求和特点。
#### 23.GMP的work stealing 和 hand off 机制
- Work stealing（工作窃取）:
- 在 Go 语言的调度器中，它用于在多线程环境下动态平衡负载。在GMP中，每个线程都维护了一个任务队列。当一个线程完成了自己的任后，它会尝试从其他线程的任务队列中窃取一个任务来执行。这样做的目的是确保各个线程的负载均衡，避免某些线程一直忙碌而其他线程于空闲状态。
- 当一个处理器的本地运行队列为空时，它会尝试从其他处理器的运行队列中窃取一半的任务。这样做的目的是在所有处理器间平衡载，从而提高资源利用率和减少等待时间。这种策略允许 Go 运行时在面对不均衡负载时保持高效。
- Hand off（任务转交）:
- 当一个线程上的协程发生阻塞时,该线程会释放绑定的处理器,并把该处理器转移给其他空闲的线程执行。这样 可以避免处理器被闲置,提高系统的效率和吞吐量。
- 总之，Go 语言运行时通过 work stealing 和 hand off 两种机制在多个处理器间动态平衡任务负载，以提高整体性能。这两种机制确保了 Go 语言在面对不同的负载和不同的硬件配置时都能保持出色的性能表现。
#### 24.GMP调度时存在那些阻塞操作？
1. 系统调用阻塞：当一个goroutine执行了系统调用（比如文件I/O、网络I/O等）时，这个goroutine会被阻塞，等待系统调用完成后才能继续执行。
2. 通道操作阻塞：当一个goroutine在读取通道时，如果通道为空，该操作会被阻塞，直到通道中有数据可读。同样地，当一个goroutine在向通道写入数据时，如果通道已满，该操作会被阻塞，直到通道有空间可写入。
3. 休眠操作阻塞：如果一个goroutine调用了time.Sleep或者相关的休眠函数，它会被阻塞，直到休眠时间到达或被其他goroutine唤醒。
4. 同步原语阻塞：使用同步原语（如互斥锁、条件变量等）时，如果一个goroutine尝试获取互斥锁或等待条件变量满足某个条件，但锁被其他goroutine占用或条件不满足，该goroutine会被阻塞，直到条件满足或获得了互斥锁。
5. runtime.Gosched()调用：当一个goroutine主动调用runtime.Gosched()函数时，它会主动让出当前线程的执行权限，使得调度器可以将其他等待执行的goroutine调度到当前线程上执行。
#### 25.GO语言的垃圾回收是怎么实现的，有哪些流程。随着版本迭代都有哪些优化？
- 垃圾回收实现：
- Go语言使用"并发标记清除（concurrent mark and sweep）"来管理和回收不再使用的内存。流程：
1. 标记阶段（Marking Phase）：垃圾回收器从根对象（如全局变量、栈上的指针等）开始，通过遍历对象图的方式标记所有可达的对象。这个过程是并发进行的，与程序的执行同时进行，不会阻塞程序的运行。
2. 并发标记阶段（Concurrent Marking Phase）：在标记阶段的同时，Go语言的垃圾回收器还会与程序的执行并发地标记新创建的对象。这个过程通过与程序的执行并行运行，以减少对程序性能的影响。
3. 清除阶段（Sweeping Phase）：在标记阶段完成后，垃圾回收器会对堆中的未标记对象进行清除。这个过程会暂停程序的执行，因为它需要遍历整个堆并回收未标记的对象。清除后的内存空间会被重新分配给新的对象使用。
4. 并发清除阶段（Concurrent Sweeping Phase）：在清除阶段完成后，Go语言的垃圾回收器会继续与程序的执行并发地清除新创建的对象。这个过程与程序的执行同时进行，以减少对程序性能的影响。
##### go的GC的版本迭代
- V1.3以前：STW（Stop The World）：
- go runtime在一定条件下（内存超过阈值或定期如2min），暂停所有任务的执行，进行mark(标记)和sweep(清扫)操作，操作完成后启动所有任务的执行。在内存使用较多的场景下，go程序在进行垃圾回收时会发生非常明显的卡顿现象。
- V1.3：Mark STW & Sweep(标记清除法)
- 1.3版本中，go runtime分离了mark和sweep操作，和以前一样，也是先暂停所有任务执行并启动mark，mark完成后马上就重新启动被暂停的任务了，而是让sweep任务和普通协程任务一样并行的和其他任务一起执行。
- v1.5：三色标记
- go 1.5正在实现的垃圾回收器“非分代的、非移动的、并发的、三色的标记清除垃圾收集器”。这种方法的mark操作是可以渐进执行的而不需每次都扫描整个内存空间，可以减少stop the world的时间。
- 1.8：混合写屏障（hybrid write barrier）
- 由于标记操作和用户逻辑是并发执行的，用户逻辑会时常生成对象或者改变对象的引用。例如把⼀个对象标记为白色准备回收时，用户逻辑突然引用了它，或者又创建了新的对象。由于对象初始时都看为白色，会被 GC 回收掉。
MUTATORTRI-COLOR MARK-SWEEPDRAVENESSABCEG稀土掘金技术社区
image.png

- 为了解决这个问题，引入了写屏障机制。
- GC 对扫描过后的对象使⽤操作系统写屏障功能来监控这段内存。如果这段内存发⽣引⽤改变，写屏障会给垃圾回收期发送⼀个信号，垃圾回收器捕获到信号后就知道这个对象发⽣改变，然后重新扫描这个对象，看看它的引⽤或者被引⽤是否改变。利⽤状态的重置实现当对象状态发⽣改变的时候，依然可以再次其引用的对象。
#### 26.三色标记法的实现原理和具体步骤。对比其他语言，还有那些垃圾回收算法。主要是对比Java 和 php
- Go语言使用三色标记法（Tricolor Mark and Sweep）作为其垃圾回收算法之一，其实现原理和步骤如下：
实现原理：
1. 所有对象初始都被标记为白色，表示这些对象尚未被扫描过。
2. 从根对象开始（如全局变量、栈中的变量等），将其引用的对象标记为灰色，表示这些对象已经被扫描过，但其引用的对象还未扫描。
3. 继续对灰色对象进行扫描，将其引用的对象标记为灰色，并将当前灰色对象标记为黑色，表示这些对象已经被扫描过，其引用的对象也已被扫描过。
4. 遍历所有白色对象，将其标记为死亡对象，进行垃圾回收。
- 具体步骤：
1. 标记阶段：从根对象开始，遍历程序中所有可达对象，将其标记为灰色，继续对灰色对象进行扫描，直到没有灰色对象为止。
2. 清除阶段：遍历所有对象，将未被标记的对象标记为白色，表示已死亡，进行垃圾回收。
3. 细化阶段：在清除阶段完成后，对存活对象进行细化处理，释放未被使用的内存空间
- 对比Java和php：
- 相比于Java的垃圾回收算法，Go语言的垃圾回收算法更加轻量级，适合于高并发、低延迟的应用场景。Java的垃圾回收算法有分代垃圾回收算法、标记-清除算法、标记-复制算法、标记-整理算法等，这些算法适用于不同的场景，具有各自的优缺点。
PHP语言的垃圾回收算法使用的是引用标记法，实现简单，存在循环引用的问题，受制于语言的特点，使用场景非常单一。
#### 27.插入，删除，混合写屏障分别是什么，解决什么问题？
- 题解：GO语言的屏障是什么，干什么的。插入屏障、删除屏障和混合写屏障是什么，分别解决什么问题
1. 屏障：Go 语言的屏障（Barrier）是一种同步机制，用于协调多个 Goroutine 的执行。在 Go 语言中，屏障通常用于等待一组 Goroutine 完成一定的任务，然后再继续执行下一步操作。
2. 作用：Go 语言的屏障机制可以帮助开发者协调多个 Goroutine 的执行，避免出现竞争条件和死锁等问题，提高程序的可靠性和性能。
3. 插入屏障：插入屏障（Barrier Insertion）是一种用于控制 Goroutine 之间交互的同步机制。插入屏障通常用于在多个 Goroutine 之间插入一个同步点，以确保它们之间的消息传递和状态同步的正确性和可靠性。
4. 删除屏障：删除屏障通（Barrier Elimination）常用于一些简单的同步操作，例如读写锁和互斥锁等，当这些锁被频繁地获取和释放时，会产生较大的开销。在这种情况下，删除屏障可以通过使用一些优化技术，例如锁消除和锁粗化，来避免不必要的同步操作，从而提高程序的性能。
5. 混合写屏障：混合写屏障（Mixed-Mode Barrier）是 Go 语言中常用的同步机制之一，可以根据具体的需求和场景选择不同的屏障实现，从而更加灵活地协调多个 Goroutine 之间的交互，确保程序的正确性和可靠性。
#### 28.GO语言什么时候会触发垃圾回收，如何调优？
Go语言的垃圾回收器是一种自动内存管理机制，用于回收不再使用的内存。有以下三种情况：
1. 定时触发：默认是垃圾回收器会在每个堆分配周期后触发，堆分配周期由 GOGC 环境变量指定，默认值为100。
2. 内存分配触发：当程序进行内存分配时，如果当前可用内存不足，垃圾回收器会被触发，以回收不再使用的内存，并将其加入内存池中供后续使用。
3. 手动触发：程序可以通过调用 runtime.GC() 函数手动触发垃圾回收器，以回收不再使用的内存。
- 调优：
1. 调整GOGC环境变量的值：垃圾回收器触发时间默认为100，如果内存使用量小，可以将其调大一些设置成200、300.
2. 减少内存分配：可以通过使用对象池、复用对象等技术来减少内存分配。
3. 避免大对象：大对象会占用大内存。
4. 使用指针：值类型相比于指针类型，值类型会被复制，增加内存。
5. 调整堆的大小，分析GC日志


## 存储篇
### MySQL篇
29.数据库三大范式
数据库三大范式（标准化）是指在关系型数据库设计中，为了避免数据不一致和数据不一致性而需要遵循的三个规范化级别。分别是：
1
第一范式（1NF）：确保每个属性都是原子性的，即每个属性都不能再分割为更小的数据单元。同时，每个属性都要具有唯一的名称，不允许重复。
2
第二范式（2NF）：保证非主键属性完全依赖于主键，即非主键属性不能只依赖于主键的部分属性。如果存在这样的情况，需要将表进行拆分，使每个表只包含一个实体类型。
3
第三范式（3NF）：保证非主键属性之间不存在供给依赖关系，即非主键属性不能依赖于其他非主键属性。如果存在这样的情况，需要将表进行拆分，使每个表只包含一个实体类型。
通过遵循这三个规范化级别，可以减少数据和数据的不一致性，提高数据库的数据的完整性和可靠性。
30.MySQL存储引擎MyIsam和InnoDB有哪些区别。
题解：很直接，就是问两个存储引擎的区别？从5个方面来对它们进行对比。
1
事务支持：MyIsam不支持事务；InnoDB支持事务，拥有ACID四大特性(原子性、一致性、隔离性、持久性)，InnoDB在高并发环境下可以更好地处理数据一致性和完整性问题(可以很好解决常见并发问题：1.脏读、2.幻读、3.不可重复读)。
2
行级锁定：InnoDB支持行级锁定，可以提高并发性能；而MyIsam则只支持表级锁定，因此在高并发环境下性能较差。
3
外键约束：InnoDB支持外键约束，MyIsam不支持，所以InnoDB可以确保数据一致性和完整性。
4
索引方式：InnoDB使用B+树索引来管理数据，可以高效地处理大量数据，而MyISAM使用B树索引，不如B+树索引高效(B+树与B树有区别)。
5
磁盘空间：InnoDB的数据存储方式比MyISAM更为复杂，因此在相同的数据集下，InnoDB需要更多的磁盘空间。
31.什么是索引？都有哪些类型？有什么优点和缺点？
索引是一种帮助MySql高效获取数据的数据结构。索引可分为主键索引与普通索引。其中普通索引也叫二级索引，类型上包括唯一索引，单列索引，联合索引，全文索引等。
优点:可以加快查询的效率。
缺点:维护起来成本很高且需要占用很多的存储空间。
32.B树和B+树的区别，聚集索引和非聚集索引的区别。什么是回表，怎么减少回表？
1
B树和B+树的区别：
B树：B树是一种自平衡的多叉树，每个节点可以包含多个关键字和子节点。所有叶子节点都在同一层，叶子节点存储了实际的数据和对应的指针。B树的查找性能较好，因为根节点到叶子节点的路径长度相等。
B+树：B+树也是一种自平衡的多叉树，与B树类似，但B+树的叶子节点之间使用链表连接，不存储数据，只存储索引和指针。所有的数据都存储在叶子节点上。B+树的查询性能更稳定，因为非叶子节点不存储实际数据，一次查询通常需要更少的磁盘I/O操作。
2
聚集索引和非聚集索引的区别：
聚集索引：在聚集索引中，数据行的物理顺序与索引的逻辑顺序相同。一张表只能有一个聚集索引，通常是主键索引。因为数据行的存储顺序与索引相同，所以聚集索引的查询速度较快。但是，当进行插入、删除或更新操作时，可能会导致数据的物理重排序，影响性能。
非聚集索引：非聚集索引中，索引的逻辑顺序与数据行的物理顺序不同。一张表可以有多个非聚集索引。非聚集索引的查询速度相对较慢，因为查询需要先找到索引，然后再通过索引找到对应的数据行。但是，插入、删除或更新数据时，对非聚集索引的维护不会导致数据的重排序，因此在这些操作上性能较好。
3
回表（Covering Index）： 回表指的是在使用非聚集索引进行查询时，MySQL还需要访问表的数据行来获取完整的查询结果。当非聚集索引中的索引列不包含查询需要的所有字段时，MySQL需要根据索引中的数据行指针回到原表中查找其它的列值，这个过程就称为回表。
4
如何减少回表：
覆盖索引：创建一个包含查询所需所有字段的索引，这样就可以避免回表操作。在一些特定场景下，覆盖索引可以显著提高查询性能。
调整查询语句：尽量选择覆盖索引，避免不必要的查询字段，只选择需要的列，减少回表的开销。
聚集索引：对于某些频繁查询的字段，可以考虑将其作为聚集索引，这样查询时可以直接使用聚集索引获取数据，避免回表操作。
综上所述，B树和B+树在索引结构上有区别，聚集索引和非聚集索引在存储和查询性能上有区别，回表是指查询时还需要访问原表的数据行，而减少回表的方法主要包括创建覆盖索引和调整查询语句等。
33.为什么会有索引失效的情况，索引调优有哪些方法？
索引失效的情况：
1
不符合最左前缀原则
2
条件中有or（若想让索引生效，只能将or条件中的每个列都加上索引），like查询以%开头、!=操作符， null值查询，
3
字符串索引，在使用是，数据一定要使用引号引用起来。若是int类型的索引，数据使不使用引号都可以。使用函数、计算操作也会导致索引失效
4
当mysql估计使用去全表扫描比使用索引快时，如表中数据量较少时
5
索引列类型不匹配：如果查询条件中的数据类型与索引列的数据类型不匹配，MySQL可能无法使用索引
索引调优：       
1
分析查询语句和数据模式：仔细分析查询语句和数据模式，了解查询的特点和使用频率，确保索引的创建和选择符合实际需求。
2
选择合适的索引策略：根据查询的特点选择合适的索引策略，包括覆盖索引、联合索引、前缀索引等，以提高查询性能。
3
优化查询语句：优化查询语句的结构和条件，避免使用不适合索引的操作符或函数操作，尽量使查询条件能够命中索引。
4
避免过度索引：避免创建过多的索引，因为过多的索引会增加数据维护的开销，并可能导致索引失效或选择不正确的索引。
5
使用索引提示：在需要的情况下，使用索引提示（Index Hint）来强制MySQL使用指定的索引，以避免错误的索引选择。
6
性能测试和监测：通过性能测试和监测工具，如EXPLAIN、Slow Query Log等，评估索引的效果，并进行必要的调整和优化
34.MySQL中的锁有哪些？什么是next-key lock？
全局锁：
1
对整个数据库实例加锁。
2
命令是Flush table with read lock(FTWRL)
3
阻塞数据的增删改、数据定义（建表、改表）和更新类事物的提交。
4
使用场景：全库逻辑备份。
表锁：分为表锁和元数据锁（MDL）。
表锁
1
表锁语法：lock tables … read/write
2
表锁解锁：unlock tables
3
表锁释放时间：客户端断开连接的时候自动释放
元数据锁
1
如何使用：MDL 不需要显式使用，在访问一个表的时候会被自动加上,已保证读写的正确性
2
什么时候加什么锁：当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁
3
加锁、解锁时机：在语句执行开始时申请，但是语句结束后并不会马上释放，而会等到整个事务提交后再释放。
行锁：
1
相比于表锁：开销大、加锁慢。但表锁不会死锁,行锁会死锁。
2
两阶段协议：行锁是在需要的时候加上锁，在事务结束时释放锁
3
Record Locks 行记录锁：
是什么：最基本的锁，锁会加在索引上；没有主键索引则会加载row_id上。查询条件是二级索引时，会回到主键索引加锁。
需要注意什么：当查询没有索引时，会走全表，把查到的每一行都加锁，在RC（读提交）下，加锁的语句执行完成后，就会直接释放掉不符合要求的行锁。因此，如果一条更新语句没有走索引，会花费极大的开销。
4
Gap Locks 间隙锁：
解决幻读的问题：在RR（可重复读）的隔离级别下，解决方法就是间隙锁。
关于幻读的问题:出现幻读也不是非常严重的问题，可以把隔离级别降到RC（读提交）这样可以提高并发性。间隙锁虽然彼此不冲突，本身也是花费一些开销，而且会和写入操作发生冲突，影响并发。
功能：锁住的是两个行之间的数据，不允许其他人向中间写入一个数据。
5
Next-Key Locks：
是什么：可以认为是记录锁和间隙锁的组合。
加锁后会发生什么：无论主键索引还是二级索引，都会加上间隙锁。 Next-Key Locks 因为包含行锁，因此会出现冲突。
6
Insert Intention Locks 插入意向锁：
只有在insert的时候会使用，和间隙锁冲突，但是彼此不冲突。
35.乐观锁与悲观锁。
悲观锁是一种比较保守的锁机制，它认为在整个事务过程中，数据很有可能会被其他事务修改，因此在对数据进行操作时，必须先对其进行加锁，以防止其他事务的干扰。悲观锁通常使用数据库的锁机制实现，如行锁、表锁等，可以有效地控制并发访问，但会对系统性能产生影响。
乐观锁是一种比较乐观的锁机制，它认为在整个事务过程中，数据很少会被其他事务修改，因此在对数据进行操作时，并不对其进行加锁，而是在事务提交之前检查数据是否被其他事务修改过，如果被修改过，则回滚事务，重新进行操作。乐观锁通常使用版本号或时间戳等机制实现，可以减少锁的使用，提高系统性能，但需要增加一些额外的开销来实现数据版本控制。
36.Mysql的事务隔离级别有哪些？MVCC是什么？
1.    读未提交：一个事务还未提交时可以被别的事务读取数据 
2.    读提交：一个事务提交之后，所做的变更可以被别的事务看到
3.    可重复读：事务在执行中用到的数据与最开始所看到的数据是一样的
4.    串行化：加锁出现冲突时 事务必须要等到前一个事务执行完成  隔离级别越高，性能就会下降。
MVCC又叫多版本并发控制，主要解决隔离性的问题；mvcc工作在读已提交和可重复读的隔离级别下，两者最大的不同是创建read view的时机不同，采用read view和undo log版本链解决，undo log是事务链表，记录有(事务)trx_id和rool_pointer(指针)，在read view 读视图中有min_trx_id(最小事务id)、max_trx_id(最大事务id)、create_trx_id(创建事务id)和m_trx_id(活跃事务id);工作原理是查看当前事务是否在当前read view中，如果在，会寻找上一个版本的事务id，如果不在，该事务就是查找的事务；读已提交和可重复读差别就在这里。
37.脏读，幻读，不可重复读是什么？是怎么解决的。
脏读、幻读和不可重复读是数据库并发控制中的三个问题。
脏读（Dirty Read）指一个事务读取了另一个事务尚未提交的数据。如果后续的事务回滚，那么前面事务读取到的数据就是无效的。
幻读（Phantom Read）指一个事务在两次查询之间，另一个事务插入了新的数据行，导致前一次查询和后一次查询的结果不一致。
不可重复读（Non-repeatable Read）指一个事务多次读取同一数据，在这个过程中，另一个事务对该数据进行了修改或删除，导致前一次读取和后一次读取的结果不一致。
为了解决这些问题，可以采用以下方法：
1
锁机制：通过加锁来保证事务的隔离性。例如，排他锁可以防止其他事务对数据进行修改，共享锁可以防止其他事务对数据进行读取和修改。
2
事务隔离级别：数据库提供了不同的事务隔离级别，如读未提交（Read Uncommitted）、读已提交（Read Committed）、可重复读（Repeatable Read）和串行化（Serializable）。根据业务需求选择合适的隔离级别。
3
MVCC（多版本并发控制）：使用版本控制的方式来实现并发控制，每个事务在读取数据时会获取一个数据版本，读取过程不会受其他事务的修改影响。
4
乐观并发控制：在事务提交前不加锁，但在更新数据时会检查数据是否被其他事务修改过，如果有冲突则进行回滚或重试。
以上是常见的解决方法，具体应该根据具体的业务场景和数据库系统来选择最合适的并发控制策略。
38.MySQL删除数据时的一些注意事项。
在使用MySQL删除数据时，有一些注意事项需要考虑，包括：
1
使用WHERE子句：确保在DELETE语句中使用WHERE子句来指定要删除的数据行。如果没有WHERE子句，将会删除整个表中的所有数据。
2
提前备份数据：在执行删除操作之前，建议先备份相关数据。这可以防止意外删除或删除错误数据后的恢复。
3
触发器：如果表上有触发器，删除数据时应该考虑这些触发器的影响，并相应地进行调整。
4
删除相关的外键关联：如果要删除的数据行与其他表中的数据存在外键关联，需要先删除或更新相关表中的数据，以避免违反外键约束。
5
执行速度：当处理大量数据时，DELETE操作可能会比较慢。可以考虑使用LIMIT子句来限制每次删除的行数，以避免对系统性能造成不必要的影响。
6
注意事务处理：如果在一个事务中执行DELETE操作，需要确保在需要时进行回滚操作，以保证数据的一致性。
总之，在执行DELETE操作时，需要仔细考虑并确保采取适当的措施来保护数据的完整性和安全性。
39.MySQL使用时的一些经验和优化。(索引怎么用，数据量大的时候如何切分，写SQL语句的一些习惯)
索引优化：设计数据库时，可以设计一些索引加快数据库常用字段的查询速度。
如何建立索引：
1
频繁作为查询条件的字段。
2
外键关系建立索引，即表中与其他表作为关联字段。
3
频繁更新的不能作为索引（因为频繁更新的字段不仅要更新数据，还要更新索引），频繁更新的表也是。
4
用不到where的字段不要建。
5
失效情况：最左匹配、索引上做一些计算、函数、类型转换、！=、is null、not null、like"%"开头、字符串不加单引号、or。
数据切分：
1
按位置切分：国家、省市城市
2
时间切分：月份、季度、年份。
3
垂直切分：如user表可以切分为账号基本信息user_basic和个人资料user_profile。
4
水平切分：如订单数据量较大，按照日期切分成order_2020、order_2021、order_2022。
SQL编写习惯：
1
explain分析一下。
2
不要使用select *。
3
尽量不要使用内置函数。
4
批量delete加limit。
5
设计表加注释。
6
设计表尽量Not Null，避免空指针。
Redis篇
40.Redis有哪些数据结构，他们底层分别是如何实现的。适合哪些场景？
Redis有以下几种常用的数据结构：
●
字符串（String）：Redis的最基本数据结构，底层实现是简单的动态字符串，适合存储简单的键值对数据。
●
列表（List）：底层实现是双向链表，可以进行快速的插入和删除操作，适合用于实现消息队列、最新消息排行等场景。
●
集合（Set）：底层实现是哈希表或者跳跃表，可以实现高效的插入、删除和查找操作，并且支持对多个集合进行交集、并集和差集等操作，适合用于去重、共同好友查找等场景。
●
哈希（Hash）：底层实现是哈希表， 可以存储多个键值对，适合用于存储对象或者记录的多个字段。
●
有序集合（Sorted Set）：底层实现是跳跃表和哈希表的结合，可以对每个元素关联一个分数，并按照分数进行排序，适合用于排行榜、按权重获取数据等场景。
这些数据结构的底层实现都是通过C语言来实现的，使用了高效的数据结构和算法。Redis通过将数据存储在内存中，并且使用单线程的方式处理请求，以提高读写性能。
根据以上数据结构的特点，Redis适合用于需要高性能、低延迟的场景，例如缓存、计数器、消息队列、实时排行榜等。
41.单个Redis实例可以存储多少个Keys?其中list set sorted set 最多能存放多少元素？
在Redis中，单个实例可以存储的Keys数量以及每种数据类型（List、Set、Sorted Set等）能存放的元素数量取决于实际使用的硬件和内存配置。
单个Redis实例可以存储多少个Keys？ Redis的Keys数量没有固定的硬性限制，它主要受限于服务器的内存和操作系统的限制。在Redis中，每个Key和Value都会占用一定的内存空间，所以实际能存储的Keys数量取决于可用内存大小以及每个Key-Value对所占用的内存。
list、set、sorted set最多能存放多少元素？ 对于List、Set和Sorted Set等数据结构，其最多能存放的元素数量同样取决于服务器的内存配置。不同的数据结构和元素大小都会影响实际能存储的数量。
List：List数据结构以双向链表的形式实现，所以其理论上可以存储非常大数量的元素。实际上，List的长度可以达到2^32-1个元素。
Set：Set是一个无序、不重复元素的集合，其最大存储量也受限于服务器内存。Redis的Set理论上可以存储约2^32-1个元素。
Sorted Set：Sorted Set是有序的Set集合，其最大存储量也取决于服务器内存大小。同样，Redis的Sorted Set理论上可以存储约2^32-1个元素。
     需要注意的是，虽然Redis理论上可以存储大量的Keys和元素，但实际应用中应该根据实际需求和硬件资源来合理规划和管理数据，以确保Redis的性能和稳定性。在处理大规模数据时，还可以采用数据分片（sharding）等技术手段来拓展Redis的存储能力和吞吐量。
42.Redis的数据淘汰机制有哪些？
Redis缓存基于内存实现的，则其缓存其容量是有限的，当出现缓存被写满的情况,Redis就需要缓存数据淘汰机制，通过一定淘汰规则将一些数据刷选出来删除，让缓存服务可再使用。
在Redis 4.0 之后，Redis 缓存淘汰策略6+2种，包括分成三大类：
不淘汰数据:
noeviction ，不进行数据淘汰，当缓存被写满后，Redis不提供服务直接返回错误。
在设置过期时间的键值对中：
volatile-random ，在设置过期时间的键值对中随机删除
volatile-ttl ，在设置过期时间的键值对，基于过期时间的先后进行删除，越早过期的越先被删除。
volatile-lru ， 基于LRU(Least Recently Used) 算法筛选设置了过期时间的键值对， 最近最少使用的原则来筛选数据
volatile-lfu ，使用 LFU( Least Frequently Used ) 算法选择设置了过期时间的键值对, 使用频率最少的键值对,来筛选数据。
在所有的键值对中：
allkeys-random， 从所有键值对中随机选择并删除数据
allkeys-lru， 使用 LRU 算法在所有数据中进行筛选
allkeys-lfu， 使用 LFU 算法在所有数据中进行筛选
43.Redis是如何做数据持久化的？
Redis在做数据持久化时，提供了两种不同的方式：快照（RDB）和追加文件（AOF）。
快照（RDB）持久化：Redis可以将内存中的数据保存到磁盘中，形成一个快照文件。快照文件是一个二进制文件，包含了某个时刻Redis中所有的数据。在Redis进行快照持久化时，会fork一个子进程，将快照数据写入磁盘。当快照文件的大小达到一定阈值时，Redis会自动触发快照操作。快照持久化的优点是备份恢复速度快，缺点是可能会丢失一些数据，因为快照是定期保存的，如果Redis在快照保存前崩溃，就会丢失数据。
追加文件（AOF）持久化：Redis可以将所有的写操作记录到AOF文件中，以此来达到数据持久化的目的。AOF文件是一个文本文件，记录了Redis服务器执行的所有写操作。当Redis重启时，会根据AOF文件重新构建出数据集。不同于快照持久化，AOF持久化是实时记录的，因此可以尽可能地保证数据的完整性。但是AOF文件会不断增大，需要定期进行压缩。
Redis默认情况下同时启用了快照持久化和AOF持久化，可以根据实际需求选择其中一种或两种方式进行数据持久化。
44.Redis的Pipeline是什么，有什么好处？
Redis Pipeline 是一种用于批量执行 Redis 命令的技术，它可以将多个命令一次性发送给 Redis 服务器，然后一次性接收服务器的响应结果，从而减少网络通信次数和客户端与服务器之间的延迟时间。Redis Pipeline 可以提高 Redis 的性能和吞吐量，特别是在需要执行大量命令的场景下，效果尤为明显。
Redis Pipeline 的好处包括：
减少网络通信次数和客户端与服务器之间的延迟时间：当需要执行多个 Redis 命令时，如果每个命令都单独发送给服务器，那么客户端需要等待服务器的响应结果，这会导致网络通信次数过多和延迟时间过长。而 Redis Pipeline 可以将多个命令一次性发送给服务器，然后一次性接收服务器的响应结果，从而减少网络通信次数和客户端与服务器之间的延迟时间。
提高 Redis 的性能和吞吐量：当需要执行大量命令时，Redis Pipeline 可以显著提高 Redis 的性能和吞吐量，因为它可以在一次网络通信中完成多个命令的执行。
45.Redis集群的一些问题。分布式，主从同步等。
Redis集群是一种分布式Redis部署模式，它将一个Redis数据库分成多个节点，每个节点可以运行在不同的物理机器上，从而提高可用性和性能。
Redis集群中的每个节点都可以是主节点或从节点，其中主节点负责接收客户端的读写请求，并将数据同步到从节点上。从节点则负责复制主节点的数据，并在主节点宕机时接管主节点的角色。Redis集群中的主从复制机制可以提高数据的可用性和可靠性。
Redis集群采用哈希槽（hash slot）的方式来实现数据分片。Redis集群将整个键空间划分为16384个哈希槽，每个槽可以存储一个或多个键值对。当客户端连接到Redis集群时，Redis集群会根据键的哈希值，将键值对分配到合适的哈希槽上。
46.使用Redis实现：异步队列，延时队列，分布式锁。以及他们的概念。
使用Redis可以实现异步队列、延时队列和分布式锁。下面是它们的概念和简要介绍：
异步队列（Async Queue）： 异步队列是一种将任务放入队列中，异步处理的机制。在Redis中，可以使用List数据结构来实现异步队列。生产者将任务放入List的尾部，消费者从List的头部获取任务进行处理。通过异步队列，可以实现任务的解耦和异步处理，提高系统的吞吐量和响应速
延时队列（Delayed Queue）： 延时队列是一种将任务延迟处理的机可以使用Sorted Set数据结构来实现延时队列。将任务放入Sorted Set，并然后由一个后台的定时任务不断地扫描Sorted Set，找出需要执行的任务进行处理。通过延时队列，可以实现任务的延迟执行，适用于定时任务、延迟任务等场景。
分布式锁（Distributed Lock）： 分布式锁在Redis中，可以使用setnx通过获取锁的客户端从而实现资源的互斥访问。通过分布式锁，可以有效地避实现简单且高效的队列和分布式锁功能。
47.缓存是如何实现高性能和高并发的？
缓存可以将经常访问的数据或计算结果保存在内存或其他快速访问的介质中，从而减少对数据库或其他慢速资源的访问，提高系统的性能和并发能力。缓存有很多种类型,基本原理大都是利用空间换时间
一些提高性能和并发能力的优化策略:
●
根据数据的访问特征选择合适的缓存淘汰策略
●
进行缓存预热,在系统启动前或在定时任务中提前将一些常用或重要的数据加载到缓存中
●
尽量的避免发生缓存穿透,击穿或雪崩,可以采取使用布隆过滤器,设置缓存过期时间,加锁队列控制,使用二级缓存等来预防
48.缓存数据一致性是什么？常用的方式有哪些？
缓存数据一致性指的是在使用缓存系统时，保证缓存数据与后端数据的一致性。当后端数据发生变化时，缓存数据也应该相应地进行更新，以确保用户获取到的数据是最新的。
常用的方式有以下几种：
●
缓存-穿透：当缓存中不存在需要的数据时，请求直接访问后端数据库，获取数据并写入缓存，从而保证缓存与数据库的一致性。
●
缓存-更新：当后端数据发生变化时，及时更新缓存中对应的数据。可以通过订阅后端数据变更的消息队列，或者在数据库更新操作完成后，同步更新缓存。
●
缓存-过期：设置缓存数据的过期时间，当数据过期时，再次访问时会触发后端数据的查询和缓存更新操作，从而保证数据的一致性。
●
缓存-失效：当后端数据发生变化时，主动使缓存失效。可以通过发布消息或者调用缓存系统提供的接口，清除对应的缓存数据。
●
读写锁：使用读写锁来保证在更新缓存时，其他并发请求不能读取旧的缓存数据，以避免脏读问题。
以上是常用的几种方式，具体选择哪种方式取决于业务需求和系统架构。
49.缓存数据的淘汰策略有哪些？
Redis提供了多种缓存数据淘汰策略，常见的策略有以下几种：
1
LRU（Least Recently Used）：最近最少使用，根据键的最近使用时间来淘汰数据。当空间不足时，优先淘汰最近最久未使用的数据。
2
LFU（Least Frequently Used）：最不经常使用，根据键的使用频率来淘汰数据。当空间不足时，优先淘汰使用频率最低的数据。
3
FIFO（First In, First Out）：先进先出，根据键的插入时间来淘汰数据。当空间不足时，优先淘汰最早插入的数据。
4
Random（随机）：随机选择需要淘汰的数据，没有具体的规则。
5
TTL（Time To Live）：设置键的过期时间，在过期时间到达后自动淘汰数据。
在Redis中，可以通过配置文件或者命令来选择使用哪种淘汰策略。默认情况下，Redis使用的是LRU策略。根据不同的业务需求和数据特点，选择合适的淘汰策略可以提高缓存效果和性能。
50缓存的“穿透”，“击穿”和“雪崩”分别是什么，要如何解决。
缓存穿透，是指查询一个一定不存在的数据，由于缓存是不命中时被动写，并且处于容错考虑，如果从 DB 查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到 DB 去查询，失去了缓存的意义。
方案一，缓存空对象。 当从 DB 查询数据为空，我们仍然将这个空结果进行缓存，具体的值需要使用特殊的标识，能和真正缓存的数据区分开。另外，需要设置较短的过期时间，一般建议不要超过 5 分钟。
方案二，BloomFilter 布隆过滤器。 在缓存服务的基础上，构建 BloomFilter 数据结构，在 BloomFilter 中存储对应的 KEY 是否存在，如果存在，说明该 KEY 对应的值不为空。
缓存雪崩，是指缓存由于某些原因无法提供服务( 例如，缓存挂掉了 )，所有请求全部达到 DB 中，导致 DB 负荷大增，最终挂掉的情况。预防和解决缓存雪崩的问题，可以从以下多个方面进行共同着手。
缓存高可用：通过搭建缓存的高可用，避免缓存挂掉导致无法提供服务的情况，从而降低出现缓存雪崩的情况。假设我们使用 Redis 作为缓存，则可以使用 Redis Sentinel 或 Redis Cluster 实现高可用。
本地缓存：如果使用本地缓存时，即使分布式缓存挂了，也可以将 DB 查询到的结果缓存到本地，避免后续请求全部到达 DB 中。如果我们使用 JVM ，则可以使用 Ehcache、Guava Cache 实现本地缓存的功能。
缓存击穿，是指某个极度“热点”数据在某个时间点过期时，恰好在这个时间点对这个 KEY 有大量的并发请求过来，这些请求发现缓存过期一般都会从 DB 加载数据并回设到缓存，但是这个时候大并发的请求可能会瞬间 DB 压垮。对于一些设置了过期时间的 KEY ，如果这些 KEY 可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑这个问题。
    区别： 
        和缓存“雪崩“”的区别在于，前者针对某一 KEY 缓存，后者则是很多KEY 。
        和缓存“穿透“”的区别在于，这个 KEY 是真实存在对应的值的。
    有两种方案可以解决：
方案一，使用互斥锁。请求发现缓存不存在后，去查询 DB 前，使用分布式锁，保证有且只有一个线程去查询 DB ，并更新到缓存。
方案二，手动过期。缓存上不设置过期时间。
51.什么是缓存预热？要如何实现预热？
缓存预热指的是在系统启动的时候，先把查询结果预存到缓存中，以便用户后面查询时可以直接从缓存中读取，以减少系统启动后或负载增加时对数据库或其他数据源的频繁访问，从而提高系统的性能和响应速度。。
实现缓存预热可以通过以下步骤：
1
确定预热的数据：确定需要预热的数据集，可以是最常被访问的热点数据、重要的业务数据或其他需要提前加载到缓存的数据。
2
编写预热脚本：编写一个预热脚本，通过读取数据源（如数据库、文件等）获取需要预热的数据，并将其存储到缓存中。可以使用缓存客户端提供的API来进行数据的读取和写入。
3
在系统启动时执行预热脚本：将预热脚本配置在系统启动脚本中，确保在系统启动时执行预热操作。这可以通过在应用程序启动时调用预热脚本的方式来实现。
4
定时预热：除了在系统启动时进行预热外，还可以定期执行预热操作，以确保缓存中的数据始终保持最新和热门。可以使用定时任务或调度工具来定期触发预热脚本。
5
监控和日志记录：在预热过程中，监控缓存的状态和性能指标，以确保预热操作的顺利进行。同时，记录预热的日志，方便后续分析和排查问题。
消息队列篇
52.什么是消息队列，主要应用场景有哪些?
消息队列是一种用于在两个独立的应用程序或组件之间传递消息的中间件。消息队列支持发送者发送消息，接收者在接收到消息时进行处理。消息可以在两个组件之间异步传递，以减少等待时间。
常见的消息队列应用场景包括：
●
异步处理：在接收到请求时，将请求写入消息队列，以便后台任务进行处理。 
●
分布式系统：在分布式系统中，消息队列可以用于在不同的服务之间进行通信。
●
流量控制：削峰填谷。在高流量系统中，消息队列可以用于缓解系统的压力，并限制请求的数量。
●
故障转移：在分布式系统中，消息队列可以用于在故障时进行故障转移，以保证系统的稳定性。
53.Kafka的架构设计是怎样的，都有哪些模块？
一个典型的Kafka架构包括Producer（生产者）、Broker（代理）、Consumer（消费者），以及ZooKeeper集群。
其中ZooKeeper负责集群元数据管理、控制器的选举等操作。
●
Producer（生产者）：负责向Kafka集群中的Broker发送消息。Producer将消息发送到指定的Topic中，每个消息可以带有Key和Value两个部分，Key用于指定消息所属的分区，Value为消息的实际内容。Producer可以以异步或同步的方式发送消息。
●
Broker（代理）：Kafka集群中的每个节点都称为Broker，负责接收、存储和转发消息。每个Broker可以同时扮演Producer和Consumer的角色，即既可以接收消息，也可以发送消息。每个Broker都可以存储多个Topic的消息，每个Topic可以被分成多个Partition，每个Partition可以由多个Broker共同承担。
●
Consumer（消费者）：负责从Kafka集群中的Broker消费消息。Consumer可以以不同的方式消费消息，包括pull和push模式。在pull模式下，consumer可以自主控制消费的速度和位置；在push模式下，consumer可以通过注册回调函数来处理消费的消息。
54.Kafka是如何保证消息的顺序性的？
kafka作为一种分布式消息队列，常见有这几种：
1
分区：Kafka中的每个主题（Topic）可以被划分为多个分区，每个分区内的消息是有序的。生产者将消息发送到指定的分区，保证了同一分区内消息的顺序性。
2
分区键：生产者发送消息时可以指定分区键，kafka会根据分区键来确定消息应该被发送到哪个分区。如果分区键相同，那么消息会被发送到同一个分区，从而保证消息的顺序性。
3
单分区消费：消费者可以通过订阅指定的分区来实现单分区消费。这样消费者只会从一个分区中读取消息，保证了消息的有序消费。
4
顺序写磁盘：消息顺序被追加到磁盘上的日志文件中。
55.Kafka是如何保证消息不丢失的？
Kafka通过以下机制来保证消息不丢失：
1
持久化存储：Kafka使用持久化的方式将消息写入磁盘，即使在发生故障或节点重启后，消息也能够被恢复。每个消息都被追加到日志文件（log）中，并保留一段时间，以便消费者可以重新读取和处理。
2
复制机制：Kafka采用分布式的复制机制来保证消息的可靠性。每个主题的分区都有多个副本分布在不同的Broker节点上。当一个Broker节点故障时，其他副本可以继续提供服务。副本之间通过同步复制或异步复制的方式保持数据的一致性。
3
ISR机制：ISR（In-Sync Replicas）是指与Leader副本保持同步的副本集合。只有ISR中的副本才能参与消息的读写操作。当副本与Leader之间的同步延迟过大或副本故障时，Kafka会将该副本从ISR中移除，直到同步恢复正常。
4
批量发送和异步确认：Kafka允许生产者将消息批量发送到Broker，可以提高生产者的吞吐量。同时，生产者可以选择异步确认机制，即不需要等待所有副本都完成写入操作，就可以继续发送下一批消息。
通过以上机制，Kafka可以在不丢失消息的前提下，提供高吞吐量、低延迟的消息传输和存储服务。但需要注意的是，仅靠Kafka本身的机制并不能完全保证消息不丢失，应结合合理的配置和监控来确保系统的可靠性。
计算机基础篇
计算机网络
56.请详细介绍一下 TCP 的三次握手和四次挥手机制？
TCP是一种可靠的传输协议，用于在网络中建立可靠的连接。TCP使用三次握手来建立连接，并使用四次挥手来关闭连接。
三次握手的过程如下：
第一步：客户端发送SYN（同步）包给服务器。这个包包含了客户端的初始序列号以及请求建立连接的标志位（SYN=1）。
第二步：服务器接收到SYN包后，会发送一个SYN/ACK（同步/确认）包给客户端。这个包包含了服务器的初始序列号以及对客户端的请求建立连接的确认。
第三步：客户端收到SYN/ACK包后，会发送一个ACK（确认）包给服务器，确认服务器的请求建立连接。此时连接已经建立，客户端和服务器可以开始进行数据传输。
通过三次握手，客户端和服务器就建立了可靠的连接。这种机制可以确保双方都同意建立连接，并且可以互相确认对方的请求和确认。
四次挥手的过程如下：
第一步：当客户端想要关闭连接时，它发送一个FIN（结束）包给服务器，表示它不再发送数据了。
第二步：服务器接收到FIN包后，发送一个ACK包给客户端，确认收到了客户端的关闭请求。
第三步：服务器发送一个FIN包给客户端，表示服务器也准备关闭连接。
第四步：客户端接收到FIN包后，发送一个ACK包给服务器，确认收到了服务器的关闭请求。此时连接已经关闭。
通过四次挥手，客户端和服务器可以优雅地关闭连接，确保双方都完成了数据传输并且确认关闭。
需要注意的是，TCP的三次握手和四次挥手是为了保证连接的可靠性和正确性。在实际应用中，可能会有一些优化和扩展的方式，例如使用TCP的连接池和快速重传机制等，以提高传输效率和可靠性。
57.为什么建立连接需要三次握手。第三次握手时，发送方可以携带其他数据吗？
建立连接需要进行三次握手是为了确保双方的通信能够可靠地进行，同时避免因网络延迟或丢包等问题导致的错误连接。
每次握手都是为了确保双方都收到了前一次握手的确认，并且能够继续下一步操作。通过三次握手，可以保证连接的可靠性，避免因网络延迟或丢包等问题导致的错误连接。
至于第三次握手时是否可以携带其他数据，根据TCP协议的规定，第三次握手时不会携带其他数据。第三次握手只是用于确认连接的建立，并不包含其他应用层数据。实际上，第三次握手时完全可以带上数据，这是一种优化。
58.为什么需要四次挥手。详细讲讲time_wait和close_wait。
TCP连接是双向传输的对等模式（即双方都可以同时向对方发送/接受数据），当有一方要关闭连接时，会发送FIN告知对方，对方回一个ACK则一个方向上的连接关闭了。而TCP是双向对等传输，故有两个方向的连接，需要两个FIN才能断开。
当服务端收到客户端发送过来的FIN断开请求时，回复ACK后只是断开了client -> server方向的连接，服务端还可以继续向客户端发送数据（若数据没有发送完）。数据发送完后，服务端也发送一个FIN，客户端回复ACK，则全部断开了
time_wait 状态表示一个连接已经完成了关闭过程，并且在等待最后的确认报文。这个状态有两个作用：一是防止上一次连接中的延迟或重复的数据包被下一次复用连接错误地接收；二是确保被动关闭方能在规定时间内正常关闭连接。如果没有 time_wait 状态，或者 time_wait 的时间太短，就可能导致数据错乱或者连接失败。这个时间可以有系统设置，默认2ms，刚好是数据包在网络上发送的时间。
close_wait 状态表示对方已经发送了关闭连接的请求，等待本端应用程序也关闭连接。这个状态的存在是为了让应用程序有机会处理完剩余的数据，并主动关闭连接。如果应用程序没有及时调用 close() 操作，就可能导致大量的 close_wait 状态积累，占用系统资源。
59.SYN超时和洪泛攻击是什么？解决策略有哪些?
SYN超时和洪泛攻击是与TCP连接建立相关的两个问题。
SYN超时（SYN Timeout）：在TCP的三次握手过程中，当服务器接收到客户端发送的SYN包后，会发送一个SYN/ACK包作为响应。但是如果客户端在一定时间内没有收到服务器的响应，就会认为连接建立失败，这个时间就称为SYN超时。SYN超时可能由于网络延迟、拥塞或网络故障等原因引起。
洪泛攻击（SYN Flood Attack）：洪泛攻击是一种网络攻击方式，攻击者通过发送大量的伪造源IP地址的SYN请求包给目标服务器，目的是耗尽服务器的资源。当服务器接收到大量的伪造SYN请求后，会为每个请求分配资源并等待客户端发送ACK包进行确认。由于伪造的源IP地址，服务器无法收到ACK包，这就导致服务器资源被大量占用，无法正常服务其他合法的请求。
解决策略：
SYN超时的解决策略：
- 增加SYN超时时间：调整服务器的SYN超时时间，使其能够容忍更长的等待时间。
- 优化网络连接：检查网络设备、链路和路由器等，确保网络连接的稳定性和低延迟。
- 加强服务器性能：提升服务器的资源和处理能力，以应对更多的连接请求。
洪泛攻击的解决策略：
- 使用防火墙：配置防火墙来过滤恶意的SYN请求流量，识别和阻止洪泛攻击。
- 启用SYN Cookie：SYN Cookie是一种防御洪泛攻击的机制，它通过在SYN/ACK包中使用加密的Cookie信息，避免消耗服务器资源。
- IP过滤和限制：通过配置IP过滤规则或使用入侵检测系统（IDS）来识别和阻止洪泛攻击的源IP地址。
- 使用负载均衡：将请求分散到多个服务器上，通过负载均衡来分担服务器资源的压力。
- 增加服务器资源：提升服务器的处理能力、网络带宽和连接数，以增加抵御洪泛攻击的能力。
这些解决策略可以帮助减轻SYN超时和洪泛攻击对TCP连接和服务器的影响，并提升网络的可靠性和安全性。
60.经典网络分层，五层 七层是哪些。TCP和UDP工作在哪一层，HTTP工作在哪一层？
经典的网络分层模型有两种：
五层协议模型（TCP/IP模型）：分为物理层、数据传输层、网络层、传输层和应用层。
七层协议模型（OSI模型）：分为物理层、数据传输层、网络层、传输层、会话层、表示层和应用层。
TCP和UDP工作在传输层（第四层），主要是数据的传输和可靠性控制。TCP是一种面向连接的协议，提供可靠的数据传输、流量控制、拥塞控制等功能；UDP是一种无连接的协议，不保证数据传输的可靠性，但传输效率高。
HTTP工作在应用层（第七层），主要负责定义客户端和服务器之间的通信规则和格式。HTTP协议使用TCP协议作为传输层协议，通过传输层协议来保证数据的传输可靠。
61.TCP和UDP有什么特点，有什么区别？
TCP和UDP是两种常见的传输层协议，用于在计算机网络中实现数据的可靠传输和通信。它们有不同的特点和适用场景，下面是它们的主要特点和区别：
TCP的特点和区别：
1
可靠性：TCP是一种可靠的传输协议，它确保数据的传输是可靠的。通过使用确认和重传机制，TCP保证数据能够完整地按序到达目的地，并且可以处理丢失、重复、乱序等问题。
2
连接导向：TCP是面向连接的协议，通信双方在进行数据传输之前需要先建立连接。连接的建立和断开都需要一定的开销，但这样可以确保通信的稳定和可靠性。
3
有序性：TCP保证数据按照发送的顺序被接收，不会出现数据乱序的情况。
4
流控制和拥塞控制：TCP具有流控制和拥塞控制机制，可以避免发送方发送过多的数据导致接收方无法及时处理，同时也能适应网络拥塞情况。
5
适用场景：TCP适用于对数据可靠性要求较高的应用场景，如文件传输、网页浏览、电子邮件等。
UDP的特点和区别：
1
不可靠性：UDP是一种不可靠的传输协议，它不保证数据的可靠传输。UDP不使用确认和重传机制，数据发送后不会等待接收方的确认，也不会重发数据，可能导致数据丢失或乱序。
2
无连接：UDP是面向无连接的协议，通信双方不需要先建立连接就可以直接发送数据。这样可以减少连接建立和断开的开销，但也意味着没有建立连接的保障。
3
无序性：UDP不保证数据按照发送顺序被接收，接收方收到数据的顺序可能与发送顺序不一致。
4
不支持流控制和拥塞控制：UDP不提供流控制和拥塞控制，发送方可以以任意速率发送数据，可能导致网络拥塞。
5
适用场景：UDP适用于对实时性要求较高、对数据可靠性要求相对较低的应用场景，如音频/视频传输、实时游戏等。
TCP和UDP是两种不同的传输层协议，TCP提供了可靠性和有序性，适用于对数据完整性要求高的场景；而UDP提供了低延迟和实时性，适用于对数据完整性要求相对较低、实时性要求高的场景。在实际应用中，根据不同的需求选择合适的传输协议可以提高网络通信的效率和性能。
1.  在浏览器的地址栏中输入URL，后续的网络都发生了什么，尽可能讲一讲。
1
解析URL，用到DNS服务确定Web服务器和文件名。
2
根据上面的信息生成http请求消息。
3
在发送消息之前，先使用DNS服务器查询服务器域名对应的IP地址（若是浏览器缓存中有这个域名的缓存，则不用再去问DNS）。
4
经过应用层、传输层（在头部添加了TCP/UDP首部）
5
经过网络层，添加报文头（头部里包含了源地址IP和目标地址IP）
6
数据链路层添加MAC头部，它包含了接收方和发送方的 MAC 地址等信息，用于两点之间的传输。（使用ARP协议，在以太网中以广播的形式找出接收方MAC地址）
7
网卡：将二进制数字信息转化为电信号，在网线上传输。（开头加上报头和起始帧分界符，在末尾加上用于检测错误的帧校验序列。）
8
交换机：交换机里的模块将电信号转换为数字信号，然后通过包末尾的 FCS 校验错误，如果没问题则放到缓冲区，接下来需要查询一下这个包的接收方 MAC 地址是否已经在 MAC 地址表中有记录了，交换机根据 MAC 地址表查找 MAC 地址，然后将信号发送到相应的端口（若找不到则将包发送给出了源端口以外的所有端口上）。
9
路由器：当转发包时，首先路由器端口会接收发给自己的以太网包，然后路由表查询转发目标，再由相应的端口作为发送方将以太网包发送出去。首先，电信号到达网线接口部分，路由器中的模块会将电信号转成数字信号，然后通过包末尾的 FCS 进行错误校验。如果没问题则检查 MAC 头部中的接收方 MAC 地址，看看是不是发给自己的包，如果是就放到接收缓冲区中，否则就丢弃这个包。完成包接收操作之后，路由器就会去掉包开头的 MAC 头部，由器会根据 MAC 头部后方的 IP 头部中的内容进行包的转发操作。
10
数据抵达服务器：倒着再来一遍
63.HTTP和HTTPS有哪些区别？
区别:
HTTPS协议需要到CA申请SSL证书,而HTTP不需要。SSL证书能够证明网站的身份,保证通信安全。
HTTPS使用的是TLS/SSL加密通信,而HTTP是明文传输。HTTPS在传输前会将数据加密,能够防止数据在传输过程中被窃取。
HTTPS协议的默认端口是443,而HTTP协议的默认端口是80。
HTTPS速度会略慢于HTTP,因为需要进行加密解密等过程。
HTTPS可以防止DNS劫持攻击,而HTTP容易受到攻击。
1.  GET和POST有哪些区别？
GET和POST是HTTP协议中常用的两种请求方法，它们在数据传输和语义上有以下区别：
1
数据位置：GET请求将参数数据附加在URL的查询字符串中，即放在URL的后面，以?符号分隔参数。例如：http://example.com/path?param1=value1而POST请求将参数数据放在请求的消息体中，作为请求的一部分。
2
数据长度限制：GET请求对URL长度有限制，不同浏览器和服务器对URL长度的限制不同，一般在几千个字符左右。而POST请求没有长度限制，因为参数数据放在请求的消息体中。
3
数据类型：GET请求的参数数据以键值对的形式出现在URL中，数据类型是明文的，可以直接在URL中看到。而POST请求的参数数据在消息体中，数据类型是隐藏的，不会直接显示在URL中，更安全。
4
数据语义：GET请求是幂等的，即多次重复请求不会产生副作用，只是获取数据，不会对服务器产生影响，可以被缓存。POST请求是非幂等的，可能会对服务器产生副作用，例如创建、更新或删除数据，不适合被缓存。
5
安全性：GET请求的参数数据暴露在URL中，容易被拦截、篡改或缓存，不适合传输敏感信息。POST请求的参数数据在消息体中，相对安全，适合传输敏感信息。
总结来说，GET适合用于获取数据，参数在URL中明文传输；而POST适合用于提交数据，参数在请求消息体中传输，更安全且没有长度限制。根据具体需求和场景，选择适合的请求方法。
65.介绍下DNS服务
1
客户端首先会发出一个 DNS 请求，问 www.server.com 的 IP 是啥，并发给本地 DNS 服务器（也就是客户端的 TCP/IP 设置中填写的 DNS 服务器地址）。
2
本地域名服务器收到客户端的请求后，如果缓存里的表格能找到 www.server.com，则它直接返回 IP 地址。如果没有，本地 DNS 会去问它的根域名服务器：“老大， 能告诉我 www.server.com 的 IP 地址吗？” 根域名服务器是最高层次的，它不直接用于域名解析，但能指明一条道路。
3
根 DNS 收到来自本地 DNS 的请求后，发现后置是 .com，说：“www.server.com 这个域名归 .com 区域管理”，我给你 .com 顶级域名服务器地址给你，你去问问它吧。”
4
本地 DNS 收到顶级域名服务器的地址后，发起请求问“老二， 你能告诉我 www.server.com 的 IP 地址吗？”
5
顶级域名服务器说：“我给你负责 www.server.com 区域的权威 DNS 服务器的地址，你去问它应该能问到”。
6
本地 DNS 于是转向问权威 DNS 服务器：“老三，www.server.com对应的IP是啥呀？” server.com 的权威 DNS 服务器，它是域名解析结果的原出处。为啥叫权威呢？就是我的域名我做主。
7
权威 DNS 服务器查询后将对应的 IP 地址 X.X.X.X 告诉本地 DNS。
8
本地 DNS 再将 IP 地址返回客户端，客户端和目标建立连接。
计算机基础
66.进程，线程和协程有什么关系和区别？
程序是一些保存在磁盘上的指令的有序集合，是静态的。进程是程序执行的过程，包括了动态创建、调度和消亡的整个过程，进程是程序资源分配管理的最小单位。
线程是操作操作系统能够进行运算调度的最小单位。线程被包含在进程之中，是进程中的实际运作单位，    一个进程内可以包含多个线程，线程是资源调度的最小单位。
协程是用户态的轻量级线程，不受操作系统的调度，而是由程序员或者库来控制。协程可以在一个线程中切换执行多个任务，实现了异步编程的效果。协程的创建和销毁完全由用户空间完成，开销非常小。
三者之间的区别:
资源分配：进程是资源分配的单位，线程和协程是资源调度的单位。
地址空间：进程有独立的地址空间，线程共享进程的地址空间，协程也共享所在线程的地址空间。
调度方式：进程和线程由操作系统调度，协程由用户或者库调度。
开销大小：进程的开销最大，线程次之，协程最小。
67.什么是并发，什么是并行？
并发是指多个任务在同一个时间段内交替进行，通过不断地切换上下文来实现同时执行的效果。
并行是指多个任务在同一个时间段内实际同时执行，并利用多个处理器或多核CPU的并行计算能力来加速任务的完成。
68.进程间的同步方式有哪些，通信方式有哪些？
进程间的同步方式有以下几种：
1
临界区（Critical Section）：通过对共享资源设置访问限制，使得同一时间只能有一个进程访问共享资源，从而避免多个进程同时访问共享资源导致的数据不一致性问题。
2
互斥量（Mutex）：通过对共享资源设置互斥锁，使得同一时间只有一个进程能够获取该锁，从而避免多个进程同时访问共享资源导致的数据不一致性问题。
3
信号量（Semaphore）：通过对共享资源设置信号量，使得进程可以通过信号量来协调对共享资源的访问，从而避免多个进程同时访问共享资源导致的数据不一致性问题。
4
事件（Event）：通过对事件的状态进行监控，使得进程可以在事件状态发生变化时得到通知，从而协调进程之间的操作。
进程间的通信方式有以下几种：
1
管道（Pipe）：管道是一种单向通信方式，可以在进程间传输数据。管道只能用于父子进程之间或者兄弟进程之间的通信。
2
命名管道（Named Pipe）：命名管道是一种单向通信方式，可以在进程间传输数据。与管道不同的是，命名管道可以用于任意进程之间的通信。
3
共享内存（Shared Memory）：共享内存是一种通过共享内存块的方式进行进程间通信的方式。多个进程可以访问同一个共享内存区域，并可以在该区域中进行数据读写。
4
信号（Signal）：信号是一种异步通信方式，进程可以通过发送信号来通知其他进程或者处理特定事件。
5
消息队列（Message Queue）：消息队列是一种通过消息传递的方式进行进程间通信的方式。多个进程可以通过消息队列来发送和接收消息。
6
套接字（Socket）：套接字是一种通过网络进行进程间通信的方式。进程可以通过套接字进行数据的发送和接收。
69.线程间的同步方式有哪些？
在线程间实现同步是为了确保多个线程按照特定的顺序执行，以避免竞态条件（race condition）和其他并发问题。以下是常见的线程间同步方式：
互斥锁（Mutex）：互斥锁是最常用的同步机制之一。一个互斥锁只能同时被一个线程获取，其他线程必须等待该线程释放锁后才能继续执行。互斥锁用于保护临界区（Critical Section），确保只有一个线程可以访问共享资源。
信号量（Semaphore）：信号量是一个计数器，用于控制对共享资源的访问。它可以允许多个线程同时访问资源，但是要限制同时访问的线程数量。信号量可以用来实现资源池的管理等场景。
条件变量（Condition Variable）：条件变量用于在线程间实现条件等待和通知。一个线程可以等待某个条件成立，当条件满足时，另一个线程可以通知等待的线程继续执行。条件变量通常和互斥锁一起使用，以确保在等待条件时不会出现竞态条件。
读写锁（Read-Write Lock）：读写锁允许多个线程同时读取共享资源，但在有线程在写入时，其他线程不能进行读或写操作。这样可以提高读操作的并发性能，适用于读多写少的场景。
屏障（Barrier）：屏障用于将多个线程分为多个阶段执行，在每个阶段的某个点上，所有线程必须等待，直到所有线程都到达屏障点，然后继续执行下一个阶段。
原子操作：原子操作是一种不可被中断的操作，要么完全执行成功，要么完全不执行，不存在中间状态。原子操作可以用于简单的同步需求，如增加或减少共享变量的值，确保在多线程环境下数据的一致性。
70.进程有哪些状态，进程是如何调度的？
新建状态（New）：进程刚被创建，但尚未被调度执行。
就绪状态（Ready）：进程已经准备好运行，但尚未被分配到CPU资源。
运行状态（Running）：进程正在运行，占用CPU资源。
阻塞状态（Blocked）：进程因为某些原因（比如等待I/O操作完成）而暂时无法运行，在这个状态下，进程不会占用CPU资源。
终止状态（Terminated）：进程已经完成了执行或者被操作系统强制终止。
进程调度的方式
a.  非剥夺调度方式，又称非抢占方式。即，只允许进程主动放弃处理机。在运行过程中即便有更紧迫的任务到达，当前进程依然会继续使用处理机，直到该进程终止或主动要求进入阻塞态。
b.  剥夺调度方式，又称抢占方式。当一个进程正在处理机上执行时，如果有一个更重要或更紧迫的进程需要使 用处理机，则立即暂停正在执行的进程，将处理机分配给更重要紧迫的那个进程。
常用的调度机制有
a.  先来先服务:非抢占式的调度算法。每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出    或被阻塞，才会继续从队列中选择第一个进程接着运行。（实现简单。但不利于短作业以及I/O密集型进程）
b.  短作业优先:非抢占式的调度算法。按照剩余执行时间最短的进程先执行。该算法可以减少平均等待时间。但是要预先知道进程的执行时间。（容易长作业饥饿，实现困难）
c.   最短剩余时间优先(SRTN)：最短作业优先的抢占式版本。当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待
d.   高响应比优先算法:非抢占式。响应比为等待时间/服务时间,响应比高的先执行，可以避免饥饿现象。（a,b方式的平衡实现）
e.   时间片轮转调度:抢占式。给每个进程都分配一个时间片，时间片执行完毕就会切换进程，执行下一个进程，依次循环。此算法容易频繁的切换进程，浪费系统资源。（公平，但频繁切换，有开销）
f.   优先级调度:有抢占式也有非抢占式：按照设定优先级执行。抢占式是动态调整优先级，如按照运行时间调整优先级。非抢占式是创建进程就设定了。（适用实时系统，对低优先级进程不利）
g.  多级反馈队列：抢占式。多级反馈队列调度算法是对其他算法的一个折中权衡。是「时间片轮转算法」和「最高优先级算法」的综合和发展。
h.  先来先服务算法的优点是公平
i.   短作业优先算法的优点是能尽快处理完短作业，平均等待/周转时间等参数很优秀
g.  时间片轮转调度算法可以让各个进程得到及时的响应
k.  优先级调度算法可以灵活地调整各种进程被服务的机会
71.什么是死锁，什么情况下会产生死锁？怎么解决？
死锁是指在多个进程（或线程）之间，每个进程都占有某些资源，同时又等待其他进程释放它所需要的资源，从而导致所有进程都无法继续执行下去的一种状态。
死锁产生的原因通常有以下几种情况：
竞争资源：不同的进程同时竞争同一个资源，但是每个进程又需要其他进程占有的资源才能继续执行。
不恰当的资源分配顺序：如果资源分配的顺序不当，可能会导致某个进程一直等待其他进程占有的资源。
循环依赖：多个进程之间形成了循环依赖，每个进程都在等待其他进程释放资源。
为了解决死锁问题，可以采取以下策略：
预防死锁：通过合理的资源分配策略、避免循环依赖等方式，尽可能地预防死锁的发生。
避免死锁：通过安全序列等方式，避免产生死锁。
检测死锁：可以通过资源分配图等方式检测死锁是否已经发生。
解除死锁：当发现死锁已经发生时，可以采取一些措施解除死锁，比如中断某个进程、回收某个进程占用的资源等。
72.中断和轮询有什么区别？
中断和轮询是计算机系统中常用的两种处理方式，它们在处理外部事件和设备响应方面有所不同。
中断是一种机制，用于在计算机系统中处理异步事件。当外部设备或程序发生了一个重要的事件，例如输入/输出请求或硬件故障，它会发送一个中断信号给处理器。中断信号会打断当前正在执行的程序，处理器会立即跳转到中断处理程序来处理这个事件。中断处理程序会对中断事件进行处理，可能包括保存当前的执行状态、执行特定的操作，然后再返回到原来的程序继续执行。中断可以实现实时响应和并发处理，适用于处理需要及时响应的事件。
轮询是一种不断查询的方式，用于检查是否有事件或设备需要处理。在轮询中，处理器会周期性地查询外部设备或程序状态，以确定是否有需要处理的事件。如果发现有事件需要处理，处理器会执行相应的操作。否则，它会继续轮询下一个设备或状态。轮询是一种主动查询的方式，需要处理器不断地占用资源来检查事件的状态。它适用于事件响应不是特别紧急的情况，或者在没有中断机制的系统中使用。
总结来说，中断是一种事件驱动的处理方式，当事件发生时会打断当前程序的执行，立即进行处理。而轮询是一种主动查询的方式，处理器会周期性地检查事件的状态并进行处理。中断适用于需要及时响应的事件，而轮询适用于相对不紧急的事件。
73.IO的多路复用
一个进程虽然任一时刻只能处理一个请求，但是处理每个请求的事件时，耗时控制在 1 毫秒以内，这样 1 秒内就可以处理上千个请求，把时间拉长来看，多个请求复用了一个进程，这就是多路复用，这种思想很类似一个 CPU 并发多个进程，所以也叫做时分多路复用。
最基础的 TCP 的 Socket 编程，它是阻塞 I/O 模型，基本上只能一对一通信，那为了服务更多的客户端，我们需要改进网络 I/O 模型。
比较传统的方式是使用多进程/线程模型，每来一个客户端连接，就分配一个进程/线程，然后后续的读写都在对应的进程/线程，这种方式处理 100 个客户端没问题，但是当客户端增大到 10000 个时，10000 个进程/线程的调度、上下文切换以及它们占用的内存，都会成为瓶颈。
为了解决上面这个问题，就出现了 I/O 的多路复用，可以只在一个进程里处理多个文件的 I/O，Linux 下有三种提供 I/O 多路复用的 API，分别是：select、poll、epoll。
select 和 poll 并没有本质区别，它们内部都是使用「线性结构」来存储进程关注的 Socket 集合。
在使用的时候，首先需要把关注的 Socket 集合通过 select/poll 系统调用从用户态拷贝到内核态，然后由内核检测事件，当有网络事件产生时，内核需要遍历进程关注 Socket 集合，找到对应的 Socket，并设置其状态为可读/可写，然后把整个 Socket 集合从内核态拷贝到用户态，用户态还要继续遍历整个 Socket 集合找到可读/可写的 Socket，然后对其处理。
很明显发现，select 和 poll 的缺陷在于，当客户端越多，也就是 Socket 集合越大，Socket 集合的遍历和拷贝会带来很大的开销，因此也很难应对 C10K。
epoll 是解决 C10K 问题的利器，通过两个方面解决了 select/poll 的问题。
epoll 在内核里使用「红黑树」来关注进程所有待检测的 Socket，红黑树是个高效的数据结构，增删改一般时间复杂度是 O(logn)，通过对这棵黑红树的管理，不需要像 select/poll 在每次操作时都传入整个 Socket 集合，减少了内核和用户空间大量的数据拷贝和内存分配。
epoll 使用事件驱动的机制，内核里维护了一个「链表」来记录就绪事件，只将有事件发生的 Socket 集合传递给应用程序，不需要像 select/poll 那样轮询扫描整个集合（包含有和无事件的 Socket ），大大提高了检测的效率。
而且，epoll 支持边缘触发和水平触发的方式，而 select/poll 只支持水平触发，一般而言，边缘触发的方式会比水平触发的效率高。
软件工程
74.简单工厂模型是什么，怎么实现？
简单工厂模式是一种创建型的设计模式,它可以根据参数的不同返回不同类的实例,被创建的实例通常都具有共同的父类或接口.简单工厂模式可以将对象的创建过程封装在一个工厂类中，使客户端不需要直接创建对象，而只需要调用工厂类的方法即可。简单工厂模式适用于产品种类较少且不需要扩展的情况。
75.单例模式有哪些？懒汉模式和饿汉模式怎么实现。
单例模式是一种设计模式，保证一个类只有一个实例，并提供全局访问点。
在单例模式中，常见的实现方式包括：
懒汉模式（Lazy Initialization）：在首次使用时才创建实例。在懒汉模式中，通过一个静态变量instance保存实例，在getInstance()方法中进行实例的延迟创建。使用synchronized关键字保证线程安全，但会影响性能。
饿汉模式（Eager Initialization）：在类加载时就创建实例。在饿汉模式中，实例在类加载时就被创建，因此不存在线程安全的问题。但如果实例初始化较为复杂，可能会导致类加载较慢。
76.观察者模式，装饰器模式。
观察者模式（Observer Pattern）是一种设计模式，它定义了对象之间的依赖关系，使得当一个对象的状态发生改变时，所有依赖于它的对象都会得到通知并被自动更新。这种模式通常用于实现事件处理系统。
例如，假设我们有一个天气预报系统，其中一个对象负责检测天气条件（我们称其为“主题”）。然后，我们可能有多个显示设备（如手机应用、电视、广播等，我们称它们为“观察者”），需要在天气条件改变时更新显示的信息。在这种情况下，我们可以使用观察者模式：每当天气检测对象更新状态时，所有的显示设备都会收到通知，并更新其显示的信息。
装饰器模式（Decorator Pattern）是一种设计模式，它允许我们动态地向一个对象添加新的行为，而无需改变其原有的代码。这是通过创建一个包装对象（即“装饰器”）来实现的，这个包装对象含有和原对象相同的接口，并且可以在保持原对象行为不变的同时添加新的行为。
例如，假设我们有一个Window类，它有一个draw方法。现在，我们希望添加一个新的特性，即在窗口周围绘制一个边框。我们可以创建一个名为BorderedWindow的新类，它包含一个Window对象，并且重写draw方法来先绘制边框，然后调用原Window对象的draw方法。这样，我们就可以在不修改Window类的情况下添加新的特性。
装饰器模式和观察者模式都是为了提高代码的灵活性和可重用性，通过解耦对象之间的关系，使得代码更容易扩展和维护。
77.如何理解软件里的“高内聚，低耦合”？
"高内聚，低耦合" 是软件设计中一个重要的原则，它强调将软件模块设计得独立、可重用、易于维护和扩展。让我们详细解释这个原则的含义：
高内聚（High Cohesion）：高内聚意味着一个模块内部的各个元素（例如函数、类、方法等）紧密相关、彼此协作，完成特定的功能或任务。一个高内聚的模块应该具有单一责任，它的功能应该是高度相关的，不涉及无关的功能。高内聚的模块更易于理解、维护和测试，因为其功能明确，功能变更也不会影响其他部分。
低耦合（Low Coupling）：低耦合意味着模块与其他模块之间的依赖关系尽量降低，模块之间的关联性应该尽可能弱化。模块之间的耦合越低，代码的灵活性和可复用性就越高。当一个模块发生变化时，低耦合的设计可以减少对其他模块的影响，降低了代码的脆弱性，并且使得系统更容易扩展和维护。
高内聚和低耦合是相互关联的，它们共同促进软件设计的优秀性：
高内聚有助于模块内部的聚焦和简化，使得代码更加清晰和易于理解。
低耦合有助于模块之间的解耦，提高了模块的复用性，降低了代码的依赖性。
高内聚和低耦合的结合可以使得代码更加模块化，提高了系统的灵活性和可维护性。
总之，高内聚，低耦合是一个重要的设计原则，它能够帮助构建更加健壮、灵活和易于维护的软件系统。
78.软件开发的流程和步骤有哪些？
分布式与微服务篇
分布式
79.谈谈CAP理论以及你对它的理解
对于一个分布式计算系统来说,不可能同时满足以下三点:
●
一致性(Consistency):对于客户端的每次读操作，要么读到的是最新的数据，要么读取失败。
●
可用性(Availability):系统提供的服务必须一直处于可用的状态，对于用户的每一个操作请求总是能够在有限的时间内返回结果，如果超过了这个时间范围，那么系统就被认为是不可用的。
●
分区容忍性(Partition tolerance):一个分布式系统中，节点组成的网络本来应该是连通的。然而可能因为某些故障，使得有些节点之间不连通了，整个网络就分成了几块区域，而数据就散布在了这些不连通的区域中，这就叫分区。
当你一个数据项只在一个节点中保存，那么分区出现后，和这个节点不连通的部分就访问不到这个数据了。这时分区就是无法容忍的。
提高分区容忍性的办法就是一个数据项复制到多个节点上，那么出现分区之后，这一数据项仍然能在其他区中读取，容忍性就提高了。然而，把数据复制到多个节点，就会带来一致性的问题，就是多个节点上面的数据可能是不一致的。要保证一致，每次写操作就都要等待全部节点写成功，而这等待又会带来可用性的问题。
总的来说就是，数据存在的节点越多，分区容忍性越高，但要复制更新的数据就越多，一致性就越难保证。为了保证一致性，更新所有节点数据所需要的时间就越长，可用性就会降低。
80.谈谈BASE理论以及你对它的理解。
BASE理论是对分布式系统设计中的一致性和可用性之间的权衡的一个理论指导。它是对ACID（原子性、一致性、隔离性、持久性）原则在分布式系统中的放松和调整。
BASE理论的含义如下：
●
基本可用（Basically Available）：系统保证在出现故障或者部分故障情况下，仍然能够提供基本的服务，即使是有损的。
●
软状态（Soft State）：系统中的状态可能会因为异步的、不同步的节点之间的数据同步延迟而存在中间状态，这种中间状态是可容忍的。与ACID的强一致性不同，BASE理论容许系统在一段时间内处于不一致状态。
●
最终一致性（Eventual Consistency）：系统在经过一段时间后，最终达到一致的状态。这意味着系统中的数据副本在一段时间内可能是不一致的，但最终会通过后台的异步数据同步操作达到一致状态。
对于BASE理论，我理解为在分布式系统中，为了追求高可用性和可伸缩性，我们可以放宽对一致性的要求。通过允许部分数据的不一致性和异步的数据更新方式，来提高系统的性能和可用性。这种放松对一致性的要求，使得系统可以更好地应对网络分区、故障恢复和大规模并发等问题。
BASE理论的应用范围主要在于互联网应用、分布式数据库、分布式缓存等场景，其中最典型的例子是NoSQL数据库，如MongoDB和Cassandra等。在这些场景下，通过使用BASE理论，可以在一定程度上提高系统的性能和可用性，追求更好的用户体验。但需要注意的是，在具体的系统设计中，需要根据业务需求和实际情况权衡使用BASE理论与ACID原则。
81.分布式服务接口的幂等性要如何设计？
设计分布式服务接口的幂等性需要考虑以下几个方面：
1
请求标识：为每个请求生成一个唯一的标识，可以通过在请求头中添加一个唯一的请求ID或者使用全局唯一标识符（UUID）来实现。这样可以确保每个请求都有一个唯一的标识。
2
幂等性检测：在接收到请求之前，需要检测该请求的标识是否已经处理过。可以通过在数据库或者缓存中记录已处理的请求标识来实现。如果标识已存在，则可以直接返回之前的处理结果，而不进行重复处理。
3
幂等性保证：在处理请求的过程中，需要保证相同标识的请求多次执行不会产生副作用。可以通过设计幂等性保证机制，例如使用数据库的唯一约束、乐观锁、悲观锁等来确保同一请求的幂等性。
4
结果返回：对于幂等性的操作，即使是重复请求，也应该返回相同的结果，而不是报错。这样可以方便客户端进行判断和处理。
通过以上设计，可以保证分布式服务接口的幂等性。但需要注意的是，在设计幂等性时需要考虑业务逻辑的特点，确保不会因为过度限制幂等性而影响业务的正常流程。
82.简单讲一下分布式事务。
分布式事务是指在分布式系统中跨越多个独立节点的事务操作，确保这些操作要么全部成功提交，要么全部回滚，以保持数据的一致性和完整性。
在分布式环境下，由于涉及多个节点，传统的单节点数据库事务的ACID属性（原子性、一致性、隔离性、持久性）很难直接适用。分布式事务的目标是在多个节点上的操作中保持ACID属性，使得整个分布式系统表现得像一个单一的事务一样。
实现分布式事务的主要挑战是如何处理节点间的协调和一致性。常用的分布式事务协议包括：
两阶段提交（Two-Phase Commit，2PC）：
第一阶段（准备阶段）：协调者向所有参与者发送准备请求，询问它们是否可以执行事务。参与者在准备就绪后将决策（同意或拒绝）发送给协调者。
第二阶段（提交阶段）：协调者根据第一阶段的反馈决定是否提交或回滚事务。如果所有参与者都同意提交，协调者会发送提交请求；否则，会发送回滚请求。
三阶段提交（Three-Phase Commit，3PC）：
三阶段提交是对两阶段提交的改进，引入了“预提交”阶段。协调者先询问参与者是否可以预提交事务，在收到参与者的反馈后再进入准备阶段。
TCC事务（Try-Confirm-Cancel）：
TCC是一种较为轻量级的分布式事务协议，适用于某些对性能要求较高的场景。TCC事务将事务操作分为三个阶段：尝试阶段（Try）、确认阶段（Confirm）和取消阶段（Cancel）。在尝试阶段，预留资源；在确认阶段，执行真正的业务操作；在取消阶段，回滚之前预留的资源。	
微服务
83.什么是微服务，微服务架构有什么特点？
微服务是一种软件开发架构风格，它将一个大型应用程序分解为多个小型、独立的服务，每个服务都可以独立部署、升级和扩展，而且它们通常使用轻量级的通信机制来相互协作。
微服务架构的特点包括：
1
松耦合：每个服务都是自治的，它们之间的通信是基于简单的API调用，这种松耦合的设计使得服务之间可以独立开发、测试、部署和扩展。
2
独立可部署：每个服务都可以独立部署，这样可以使得更新或升级某个服务不会影响到整个应用程序。
3
弹性和可伸缩：由于每个服务都是独立的，所以可以根据需求对每个服务进行水平扩展，从而实现系统的弹性和可伸缩性。
4
技术多样性：不同的服务可以使用不同的编程语言、框架和技术栈，这样可以充分发挥每个技术的优势。
5
分布式管理：微服务架构通常需要一定的分布式管理能力，例如服务发现、负载均衡、故障恢复等等。
6
总的来说，微服务架构可以帮助开发人员更快、更灵活地构建和维护复杂的应用程序。
84.单片，SOA和微服务有什么区别？
单片（Monolithic），SOA（Service-Oriented Architecture）和微服务（Microservices）是三种不同的软件架构方式。
单片架构：单片架构是一种传统的软件架构方式，将整个应用作为一个单一的、独立的代码库和部署单元。在单片架构中，所有的功能模块都集中在一起，通过共享数据和函数调用来实现应用的各个功能。这种架构方式的优点是简单、易于开发和部署，但当应用规模增大时，单片架构会导致代码耦合度高、维护困难、扩展性差等问题。
SOA架构：SOA架构是一种面向服务的架构方式，将应用划分为一组相互独立且可重用的服务。每个服务具有明确定义的接口和功能，通过消息通信或远程调用来实现服务之间的交互。SOA注重服务的松耦合和复用性，通过服务之间的协作组合来实现应用功能。SOA架构的优点是灵活、可扩展、可维护，但需要考虑服务间通信的复杂性和性能开销。
微服务架构：微服务架构是一种将应用拆分为一组小型、独立的服务的架构方式。每个微服务都专注于某个具体的业务功能，并有自己独立的数据库和部署单元。微服务之间通过API调用或消息传递进行通信。微服务架构强调服务的自治性和独立性，可以独立开发、测试、部署和扩展每个服务。它的优点是高度可扩展、可维护性强，但需要面对服务间的一致性、分布式事务和运维复杂性等挑战。
总结来说，单片架构是传统的、集中式的架构方式；SOA架构是面向服务的架构方式，强调服务的复用和协作；微服务架构是一种将应用拆分为小型、独立服务的架构方式，强调服务的自治性和独立性。每种架构方式都有其适用的场景和优劣势，选择合适的架构方式需要考虑业务需求、团队规模、部署环境等因素。
85.什么是领域驱动模型（DDD）？怎么理解DDD？
领域驱动设计（Domain-Driven Design，简称DDD）是一种软件开发方法论，旨在帮助开发人员更好地理解和解决复杂业务领域中的问题。DDD强调将业务领域作为关注重点，并在软件设计中体现出来。
在DDD中，"领域"是指业务中的特定领域，例如电子商务、银行服务、物流管理等。领域驱动设计的目标是将这些业务领域的知识和规则融入到软件设计和开发中，以更好地满足业务需求。
理解DDD可以从以下几个方面来思考：
领域模型（Domain Model）：领域模型是对业务领域的概念和规则的抽象和建模。它包括实体（Entity）、值对象（Value Object）、聚合（Aggregate）、领域服务（Domain Service）等，用于描述业务领域中的实体、属性、关系和行为。
上下文边界（Bounded Context）：一个领域可以由多个上下文边界组成，每个上下文边界都有自己的语言、模型和规则。上下文边界可以帮助团队更好地理解和划分业务领域，保持模型的内聚性和一致性。
领域驱动设计的模式和原则：DDD提供了一些模式和原则，如聚合根（Aggregate Root）、领域事件（Domain Event）、领域驱动设计的分层架构等，用于指导开发人员进行领域驱动设计。
战略设计（Strategic Design）和战术设计（Tactical Design）：DDD提供了战略设计方法来定义上下文边界、领域通用语言和领域模型之间的关系。而战术设计则关注如何在每个上下文边界中实现具体的领域模型。
总之，DDD是一种将业务领域的知识和规则融入到软件设计和开发中的方法论。它强调通过领域模型的建立和应用，使得软件系统更加贴近真实业务需求，提高系统的可维护性、可扩展性和可理解性。